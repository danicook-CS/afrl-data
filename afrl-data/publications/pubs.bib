@Book{BookPF,
  author = 	 {Ioannis Rekleitis},
  title = 	 {Particle Filters for Mobile Robot Localization: A Practitioner’s Tutorial},
  publisher = 	 {Y1d Books},
  year = 	 2010,
  isbn = 	 {978-0-9809915-3-6, 2010-12},
abstract = {Abstract:},
label ={B1},
category={Books},
pdf = "PFbook.pdf"
}

@article{XanthidisJIRS2020,
author = {Marios Xanthidis, Joel M. Esposito, Ioannis~Rekleitis, and Jason M. O'Kane},
title = {Motion Planning by Sampling in Subspaces of Progressively Increasing Dimension},
journal = {Journal of Intelligent \& Robotic Systems},
volume = {n/a},
number = {n/a},
pages = {},
doi = {10.1007/s10846-020-01217-w},
abstract = {},
label ={J15},
category={Journal Papers},
pdf = ""
}

@article{KalaitzakisFSR2020,
author = {Kalaitzakis, Michail and Cain, Brennan and Vitzilaios, Nikolaos and Rekleitis, Ioannis and Moulton, Jason},
title = {A marsupial robotic system for surveying and inspection of freshwater ecosystems},
journal = {Journal of Field Robotics},
year = {2021},
volume = {38},
number = {1},
pages = {121-138},
keywords = {cooperative robots, environmental monitoring, robot teaming},
doi = {10.1002/rob.21957},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/rob.21957},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.21957},
abstract = {Abstract Freshwater ecosystems are vast areas that are constantly changing and evolving. To maintain the ecosystem as well as the structures located close to bodies of water, frequent monitoring is required. Although dangerous and time consuming, manual operations are the conventional way of monitoring such areas. Recently, Autonomous Surface Vehicles (ASVs) have been proposed to undertake the monitoring task. As any other platform, ASVs have limitations, such as a restricted point of view and access only where the water is sufficiently deep. Unmanned Aerial Vehicles (UAVs) can fly over any terrain and provide a “bird's-eye-view” of the environment. However, UAVs have limited operational time due to power constraints. Heterogeneous marsupial robotic systems use different types of robots to augment their operation envelope, taking advantage of their individual strengths. A marsupial survey system comprised an ASV and a UAV for freshwater monitoring is developed and presented in this paper. This system is able to complete long missions and reach remote locations while also being able to generate detailed maps and inspections of points of interest. The system was thoroughly tested during a 6-month period in a number of field deployments in freshwater ecosystems at Lake Murray and at the Congaree River, SC, USA, to validate its capabilities.},
label ={J14},
category={Journal Papers},
pdf = "16744683.pdf"
}


@article{Elsherif2019,
author={Laila Elsherif and Noah Sciaky and Carrington A. Metts and Md Modasshir and Ioannis Rekleitis and Christine A. Burris and Joshua A. Walker and Nadeem Ramadan and Tina M. Leisner and Stephen P. Holly and Martis Cowles and Kenneth I. Ataga and Joshua N. Cooper and Leslie V. Parise},
title={Machine Learning to Quantitate Neutrophil NETosis},
journal={Scientific Reports},
year={2019},
volume={9},
number={1},
publisher={Nature Publishing Group},
doi={https://doi.org/10.1038/s41598-019-53202-5},
pages={1-12},
language={English},
abstract={Abstract: We introduce machine learning (ML) to perform classification and quantitation of images of nuclei from human blood neutrophils. Here we assessed the use of convolutional neural networks (CNNs) using free, open source software to accurately quantitate neutrophil NETosis, a recently discovered process involved in multiple human diseases. CNNs achieved >94\% in performance accuracy in differentiating NETotic from non-NETotic cells and vastly facilitated dose-response analysis and screening of the NETotic response in neutrophils from patients. Using only features learned from nuclear morphology, CNNs can distinguish between NETosis and necrosis and between distinct NETosis signaling pathways, making them a precise tool for NETosis detection. Furthermore, by using CNNs and tools to determine object dispersion, we uncovered differences in NETotic nuclei clustering between major NETosis pathways that is useful in understanding NETosis signaling events. Our study also shows that neutrophils from patients with sickle cell disease were unresponsive to one of two major NETosis pathways. Thus, we demonstrate the design, performance, and implementation of ML tools for rapid quantitative and qualitative cell analysis in basic science.},
label ={J13},
category={Journal Papers},
pdf = "s41598-019-53202-5"
}

@article{QuattriniLiAR2019,
author={Alberto Quattrini Li and Phani Krishna Penumarthi and Jacopo Banfi and Nicola Basilico and Jason M. O’Kane and Ioannis Rekleitis and Srihari Nelakuditi and Francesco Amigoni},
title={Multi-robot online sensing strategies for the construction of communication maps},
journal={Autonomous Robots},
year={2019},
volume={},
publisher={Springer},
doi={https://doi.org/10.1007/s10514-019-09862-3},
pages={1-21},
month={May},
language={English},
abstract={Abstract: This paper tackles the problem of constructing a communication map of a known environment using multiple robots. A communication map encodes information on whether two robots can communicate when they are at two arbitrary locations and plays a fundamental role for a multi-robot system deployment to reliably and effectively achieve a variety of tasks, such as environmental monitoring and exploration. Previous work on communication map building typically considered only scenarios with a fixed base station and designed offline methods, which did not exploit data collected online by the robots. This paper proposes Gaussian Process-based online methods to efficiently build a communication map with multiple robots. Such robots form a mesh network, where there is no fixed base station. Specifically, we provide two leader-follower online sensing strategies to coordinate and guide the robots while collecting data. Furthermore, we improve the performance and computational efficiency by exploiting prior communication models that can be built from the physical map of the environment. Extensive experimental results in simulation and with a team of TurtleBot 2 platforms validate the approach.},
label ={J12},
category={Journal Papers},
pdf = "AR2019CommunicationMaps.pdf"
}


@article{BanfiAR2017,
author={ Jacopo Banfi and Alberto Quattrini Li and Ioannis Rekleitis and Francesco Amigoni and Nicola Basilico},
title={Strategies for coordinated multirobot exploration with recurrent connectivity constraints},
journal={Autonomous Robots},
year={2017},
volume={},
publisher={Springer},
doi={http://dx.doi.org/10.1007/s10514-017-9652-y},
pages={1-20},
month={July},
language={English},
abstract = {Abstract: During several applications, such as search andrescue, robots must discover new information about the envi-ronment and, at the same time, share operational knowledgewith a base station through an ad hoc network. In this paper,we design exploration strategies that allow robots to coor-dinate with teammates to form such a network in order tosatisfy recurrent connectivity constraints—that is, data mustbe shared with the base station when making new observa-tions at the assigned locations. Current approaches lack inﬂexibility due to the assumptions made about the commu-nication model. Furthermore, they are sometimes inefﬁcientbecause of the synchronous way they work: new plans areissued only once all robots have reached their goals. Thispaper introduces two novel asynchronous strategies thatwork with arbitrary communication models. In this paper, ‘asynchronous’ means that it is possible to issue new plansto subgroups of robots, when they are ready to receive them.First, we propose a single-stage strategy based on IntegerLinear Programming for selecting and assigning robots tolocations. Second, we design a two-stage strategy to improvecomputational efﬁciency, by separating the problem of loca-tions’ selection from that of robot-location assignments.Extensive testing both in simulation and with real robotsshow that the proposed strategies provide good situationawareness at the base station while efﬁciently exploring the environment.},
label ={J11},
category={Journal Papers},
pdf = "AR2017Exploration.pdf"
}


@article{StOngeRAS2017,
author={David St-Onge and Pierre-Yves Breches and Inna Sharf and Nicolas Reeves and Ioannis Rekleitis and Patrick Abouzakhm and Yogesh Girdhar and Adam Harmat and Gregory Dudek and Philippe Giguere},
title={Control, localization and human interaction with an autonomous lighter-than-air performer},
journal={Robotics and Autonomous Systems},
year={2017},
volume={88},
keywords={Robotic blimp, Robotic art, Human–robot interaction, Dynamic modeling, Mobile robotics, Airship Theater},
publisher={Elsevier},
doi={http://dx.doi.org/10.1016/j.robot.2016.10.013},
pages={165-186},
month={Feb.},
language={English},
abstract = {Abstract: Due to the recent technological progress, Human–Robot Interaction (HRI) has become a major field of research in both engineering and artistic realms, particularly so in the last decade. The mainstream interests are, however, extremely diverse: challenges are continuously shifting, the evolution of robot' skills, as well as the advances in methods for understanding their environment radically impact the design and implementation of research prototypes. When directly deployed in a public installation or artistic performances, robots help foster the next level of understanding in HRI. To this effect, this paper presents a successful interdisciplinary art-science-technology project, the Aerostabiles, leading to a new way of conducting HRI research. The project consists of developing a mechatronic, intelligent platform embodied in multiple geometric blimps – cubes – that hover and move in the air. The artistic context of this project required a number of advances in engineering on the aspects of localization and control systems, flight dynamics, as well as interaction strategies, and their evolution through periods of collective activities called "research–creation residencies". These events involve artists, engineers, and performers working in close collaboration, sometimes, over several weeks at a time. They generate fruitful exchanges between all researchers, but most of all, they present a unique and creative way to direct and focus the robotics development. This paper represents an overview of the technical contributions from a range of expertise through the artistic drive of the Aerostabiles project.},
label ={J10},
category={Journal Papers},
pdf = "RASCubes2017.pdf"
}

@article{XuAR2014,
author={Anqi Xu  and Chatavut Viriyasuthee and Ioannis Rekleitis},
title={Efficient complete coverage of a known arbitrary environment with applications to aerial operations},
journal={Autonomous Robots},
year={2014},
issn={0929-5593},
volume={36},
number={4},
doi={10.1007/s10514-013-9364-x},
publisher={Springer US},
keywords={Path planning; Coverage; Unmanned aerial vehicles},
pages={365-381},
language={English},
abstract = {Abstract: The problem of coverage of known space arises in a multitude of domains, including search and rescue, mapping, and surveillance. In many of these applications, it is desirable or even necessary for the solution to guarantee both the complete coverage of the free space, as well as the efficiency of the generated trajectory in terms of distance traveled. A novel algorithm is introduced, based on the boustrophedon cellular decomposition technique, for computing an efficient complete coverage path for a known environment populated with arbitrary obstacles. This hierarchical approach first partitions the space to be covered into non-overlapping cells, then solves the Chinese postman problem to compute an Eulerian circuit traversing through these cells, and finally concatenates per-cell seed spreader motion patterns into a complete coverage path. Practical considerations of the coverage system are also explored for operations with a non-holonomic aerial vehicle. The effects of various system parameters are evaluated in controlled environments using a high-fidelity flight simulator, in addition to over 200 km of in-field flight sessions with a fixed-wing unmanned aerial vehicle.},
label ={J9},
category={Journal Papers},
pdf = "ARCover2014.pdf"
}

@Article{RekleitisAR2012,
  author = 	 {Ioannis Rekleitis and Jean-Luc Bedwani and Erick Dupuis and Tom Lamarche and Pierre Allard},
  title = 	 {Autonomous over-the-horizon navigation using LIDAR data},
  journal = 	 {Autonomous Robots},
  year = 	 2012,
  DOI = 	 {10.1007/s10514-012-9309-9},
abstract = {Abstract: In this paper we present the approach for autonomous planetary exploration developed at the Canadian Space Agency. The goal of this work is to enable autonomous navigation to remote locations, well beyond the sensing horizon of the rover, with minimal interaction with a human operator. We employ LIDAR range sensors due to their accuracy, long range and robustness in the harsh lighting conditions of space. Irregular Triangular Meshes (ITMs) are used for representing the environment, providing an accurate, yet compact, spatial representation. In this paper a novel path-planning technique through the ITM is introduced, which guides the rover through flat terrain and safely away from obstacles. Experiments performed in CSA's Mars emulation terrain, validating our approach, are also presented.},
category={Journal Papers},
label ={J8 },
pdf = "ARCSA2012.pdf"
}


@Article{RekleitisAMAI2008,
  author = 	 {Ioannis Rekleitis and Ai Peng New and Edward Samuel Rankin and Howie Choset},
  title = 	 {Efficient Boustrophedon Multi-Robot Coverage: an algorithmic approach},
  journal = 	 {Annals of Mathematics and Artificial Intelligence},
  year = 	 2008,
  doi =          {https://doi.org/10.1007/s10472-009-9120-2},
  volume = 	 {52},
  number = 	 {2-4},
  pages = 	 {109-142},
  month = 	 {Apr.},
abstract = {Abstract:This paper presents algorithmic solutions for the complete coverage path planning problem using a team of mobile robots. Multiple robots decrease the time to complete the coverage, but maximal efficiency is only achieved if the number of regions covered multiple times is minimized. A set of multi-robot coverage algorithms is presented that minimize repeat coverage. The algorithms use the same planar cellbased decomposition as the Boustrophedon single robot coverage algorithm, but provide extensions to handle how robots cover a single cell, and how robots are allocated among cells. Specifically, for the coverage task our choice of multi-robot policy strongly depends on the type of communication that exists between the robots.  When the robots operate under the line-of-sight communication restriction, keeping them as a team helps to minimize repeat coverage. When communication between the robots is available without any restrictions, the robots are initially distributed through space, and each one is allocated a virtually-bounded area to cover. A greedy auction mechanism is used for task/cell allocation among the robots. Experimental results from different simulated and real environments that illustrate our approach for different communication conditions are presented.},
category={Journal Papers},
label ={J7},
pdf = "RekleitisCoverageJournal.pdf"
}

@Article{MartinRAM2008,
  author = 	 {Eric Martin and R\'{e}gent L'Archev\^{e}que and S\'{e}bastien Gemme and Ioannis Rekleitis and Erick Dupuis},
  title = 	 {The Avatar Project: Remote Robotic Operations Conducted from the International Space Station},
  journal = 	 {IEEE Robotics and Automation Magazine},
  year = 	 2008,
  doi =          {http://dx.doi.org/10.1109/mra.2008.929926},
  volume = 	 14,
  number = 	 4,
  pages = 	 {20-27},
  month = 	 {Dec.},
abstract = {Abstract: CSA (Canadian Space Agency) is currently developing and conducting a series of experiments dubbed Avatar to investigate different command and control schemes allowing operators to interact with robots in space or on other planets. The objective of the Avatar experiments is to develop and test concepts in support of future space exploration missions. Although some of the concepts can be (and have been!) tested on Earth by simulating space-relevant communication links, the benefits of conducting them from the ISS are numerous. First, the usage of an intermittent amateur radio link has raised several issues regarding the robustness of the software: it is impossible to cheat when the communication link really goes down. It has also allowed the team to develop unique operational expertise. One final advantage not to be neglected is the fact that these experiments will have provided flight heritage to the command and control concepts described in this article and to the software that was used to implement them. Such heritage is precious in the traditionally conservative space community.},
category={Journal Papers},
label ={J6 },
pdf = "AvatarRAM.pdf"
}

@Article{RekleitisJFR2007,
  author = 	 {Ioannis Rekleitis and Eric Martin and Guy Rouleau and R\'{e}gent L'Archev\^{e}que and Kourosh Parsa and Erick Dupuis},
  title = 	 {Autonomous Capture of a Tumbling Satellite},
  journal = 	 {Journal of Field Robotics, Special Issue on Space
  Robotics, Part II},
  year = 	 2007,
  doi =          { https://doi.org/10.1002/rob.20194},
  volume =       24,
  number =       {4},
  pages =	 {275--296},
  month =	 {Apr.},
abstract = {Abstract: In this paper, we describe a framework for the autonomous capture and servicing of satellites. The work is based on laboratory experiments that illustrate the autonomy and remote-operation aspects. The satellite-capture problem is representative of most on-orbit robotic manipulation tasks where the environment is known and structured, but it is dynamic since the satellite to be captured is in free flight. Bandwidth limitations and communication dropouts dominate the quality of the communication link. The  satellite-servicing scenario is implemented on a robotic test-bed in laboratory settings. The communication aspects were validated in transatlantic tests.},
category={Journal Papers},
label ={J5 },
pdf = "Rekleitis-Martin-Rouleau-Larcheveque-Parsa-Dupuis-2007.pdf"
}

@Article{RekleitisRAS2006,
  author = 	 {Ioannis Rekleitis and David Meger and Gregory Dudek},
  title = 	 {Simultaneous Planning, Localization, and Mapping in a Camera Sensor Network},
  journal = 	 {Robotics and Autonomous Systems},
  year = 	 2006,
  doi =          {https://doi.org/10.1007/4-431-35881-1_16},
  volume = 	 {54},
  number = 	 {11},
  pages = 	 {921--932},
  month = 	 {Nov.},
abstract = {Abstract: In this paper we examine issues of localization, exploration, and planning in the context of a hybrid robot/camera-network system. We exploit the ubiquity of camera networks to use them as a source of localization data. Since the Cartesian position of the cameras in most networks is not known accurately, we consider the issue of how to localize such cameras. To solve this hybrid localization problem, we subdivide it into a local problem of camera-parameter estimation combined with a global planning and navigation problem. We solve the local camera-calibration problem by using fiducial markers embedded in the robot and by selecting robot trajectories in front of each camera that provide good calibration and field-of-view accuracy.We propagate information among the cameras and the successive positions of the robot using an Extended Kalman filter. Finally, we move the robot between the camera positions to explore the network using heuristic exploration strategies.  The paper includes experimental data from an indoor office environment as well as tests on simulated data sets.},
category={Journal Papers},
label ={J4},
pdf = "SNetSPLAM.pdf"
}

@Article{LisienTRO2005,
  author = 	 {Brad Lisien and Deryck Morales and David Silver and George Kantor and Ioannis  Rekleitis and Howie Choset},
  title = 	 {The Hierarchical Atlas},
  journal = 	 {IEEE Transactions on Robotics },
  year = 	 2005,
  doi  =         {https://doi.org/10.1109/TRO.2004.837237},
  volume =	 21,
  number =	 3,
  pages =	 {473-481},
  month =	 {Jun.},
abstract = {Abstract: This paper presents a new map specifically designed for robots operating in large environments and possibly in higher dimensions. We call this map the hierarchical atlas because it is a multilevel and multiresolution representation. For this paper, the hierarchical atlas has two levels: at the highest level there is a topological map that organizes the free space into submaps at the lower level. The lower-level submaps are simply a collection of features. The hierarchical atlas allows us to perform calculations and run estimation techniques, such as Kalman filtering, in local areas without having to correlate and associate data for the entire map. This provides a means to explore and map large environments in the presence of uncertainty with a process named hierarchical simultaneous localization and mapping. As well as organizing information of the free space, the map also induces well-defined sensor-based control laws and a provably complete policy to explore unknown regions. The resulting map is also useful for other tasks such as navigation, obstacle avoidance, and global localization. Experimental results are presented showing successful map building and subsequent use of the map in large-scale spaces. },
category={Journal Papers},
label ={J3},
pdf = "HAtlasTRO2005.pdf"
}

@Article{RoumeliotisRekleitisAR2004,
  author = 	 {Stergios I. Roumeliotis and Ioannis  Rekleitis},
  title = 	 {Propagation of Uncertainty in Cooperative Multirobot
  Localization: Analysis and Experimental Results},
  journal = 	 {Autonomous Robots},
  year = 	 {2004},
  doi  =         {https://doi.org/10.1023/B:AURO.0000032937.98087.91},
  volume = 	 {17},
  number = 	 {1},
  pages = 	 {41-54},
  month = 	 {Jul.},
  abstract = {Abstract: This paper examines the problem of cooperative localization for the case of large groups of mobile robots. A Kalman filter estimator is implemented and tested for this purpose. The focus of this paper is to examine the effect on localization accuracy of the number $N$ of participating robots and the accuracy of the sensors employed. More specifically, we investigate the improvement in localization accuracy per additional robot as the size of the team increases.  Furthermore, we provide an analytical expression for the upper bound on the positioning uncertainty increase rate for a team of $N$ robots as a function of $N$, the odometric and orientation uncertainty for the robots, and the accuracy of a robot tracker measuring relative positions between pairs of robots. The analytical results derived in this paper are validated both in simulation and experimentally for different test cases.},
 category={Journal Papers},
 label = {J2},
  pdf   = "AR2004.pdf"  
}

@Article{Rekleitis2001c,
author = {Ioannis  Rekleitis and Gregory Dudek and Evangelos Milios},
title = {Multi-Robot Collaboration for Robust Exploration},
journal = {Annals of Mathematics and Artificial Intelligence},
year = 2001,
doi = {https://doi.org/10.1023/a:1016636024246},
volume = 31,
number = {1-4},
pages = {7-40},
abstract = {Abstract: This paper presents a new sensing modality for multirobot exploration. The approach is based on using a pair of robots that observe each other, and act in concert to reduce odometry errors. We assume the robots can both directly sense nearby obstacles and see each other. The proposed approach improves the quality of the map by reducing the inaccuracies that occur over time from dead reckoning errors. Furthermore, by exploiting the ability of the robots to see each other, we can detect opaque obstacles in the environment independently of their surface reflectance properties. Two different algorithms, based on the size of the environment, are introduced, with a complexity analysis, and experimental results in simulation and with real robots.},
category={Journal Papers},
label ={J1 },
pdf = "CLjournal2001.pdf"
}

@InCollection{Dupuis-LArcheveque-Allard-Rekleitis-Martin-2006,
  author = 	 {Erick Dupuis and R{\'e}gent L'Archev{\^e}que and Pierre Allard and Ioannis Rekleitis and Eric Martin},
  title = 	 {A Framework for Autonomous Space Robotics Operations},
  booktitle = 	 {Intelligent Space Robotics},
  publisher = {TSI Press},
  year = 	 2006,
  editor = 	 {Ayanna Howard and Eddie Tunstel},
  abstract = {Abstract: },
  category={Book Chapters},
  label ={B1},
  pdf = "Dupuis-LArcheveque-Allard-Rekleitis-Martin-2006.pdf"
 }


@InProceedings{JoshiIROS2020,
  author = 	 {Bharat Joshi, Md Modasshir, Travis Manderson, Hunter Damron, Marios Xanthidis, Alberto Quattrini Li, Ioannis Rekleitis, and Gregory Dudek},
  title = 	 {DeepURL: Deep Pose Estimation Framework for Underwater Relative Localization},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2020,
  pages = 	 {accepted},
  address = 	 {Las Vegas, NV},
  abstract = {In this paper, we propose a real-time deep-learning approach for determining the 6D relative pose of Autonomous Underwater Vehicles (AUV) from a single image. A team of autonomous robots localizing themselves, in a communicationconstrained underwater environment, is essential for many applications such as underwater exploration, mapping, multirobot convoying, and other multi-robot tasks. Due to the profound difficulty of collecting ground truth images with accurate 6D poses underwater, this work utilizes rendered images from the Unreal Game Engine simulation for training. An image translation network is employed to bridge the gap between the rendered and the real images producing synthetic images for training. The proposed method predicts the 6D pose of an AUV from a single image as 2D image keypoints representing 8 corners of the 3D model of the AUV, and then the 6D pose in the camera coordinates is determined using RANSACbased PnP. Experimental results in underwater environments (swimming pool and ocean) with different cameras demonstrate the robustness of the proposed technique, where the trained system decreased translation error by 75.5\% and orientation error by 64.6\% over the state-of-the-art methods.},
  label ={C91},
  category = {Conference Papers},
  pdf = "IROS20_1754_FI.pdf",
  vid = "IROS20_1754_VI_fi.mp4"
  }


@InProceedings{XanthidisICRA2020,
  author = 	 {Marios Xanthidis and Nare Karapetyan and Hunter Damron and Sharmin Rahman and James Johnson and Allison O'Connell and Jason O'Kane and Ioannis Rekleitis},
  title = 	 {Navigation in the Presence of Obstacles for an Agile Autonomous Underwater Vehicle},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = 	 2020,
  pages = 	 {892--899},
  address = 	 {Paris, France},
  abstract = {Abstract: Navigation underwater traditionally is done by keeping a safe distance from obstacles, resulting in “fly-overs” of the area of interest. Movement of an autonomous underwater vehicle (AUV) through a cluttered space, such as a shipwreck or a decorated cave, is an extremely challenging problem that has not been addressed in the past. This paper proposes a novel navigation framework utilizing an enhanced version of Trajopt for fast 3D path-optimization planning for AUVs. A sampling-based correction procedure ensures that the planning is not constrained by local minima, enabling navigation through narrow spaces. Two different modalities are proposed: planning with a known map results in efficient trajectories through cluttered spaces; operating in an unknown environment utilizes the point cloud from the visual features detected to navigate efficiently while avoiding the detected obstacles. The proposed approach is rigorously tested, both on simulation and in-pool experiments, proven to be fast enough to enable safe real-time 3D autonomous navigation for an AUV.},
  label ={C90},
  category = {Conference Papers},
  pdf = "ICRA20_1758_FI.pdf",
  vid = "ICRA20_1758_VI_fi.mp4"
  }

@InProceedings{ModasshirICRA2020,
  author = 	 {Md Modasshir and Ioannis Rekleitis},
  title = 	 {Augmenting Coral Reef Monitoring with an Enhanced Detection SystemAugmenting Coral Reef Monitoring with an Enhanced Detection System},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = 	 2020,
  pages = 	 {1874--1880},
  address = 	 {Paris, France},
  abstract = {Abstract: Coral species detection underwater is a challenging problem. There are many cases when even the experts (marine biologists) fail to recognize corals, hence limiting ground truth annotation for training a robust detection system. Identifying coral species is fundamental for enabling the monitoring of coral reefs, a task currently performed by humans, which can be automated with the use of underwater robots. By employing temporal cues using a tracker on a high confidence prediction by a convolutional neural network-based object detector, we augment the collected dataset for the retraining of the object detector. However, using trackers to extract examples also introduces hard or mislabelled samples, which is counterproductive and will deteriorate the performance of the detector. In this work, we show that employing a simple deep neural network to filter out hard or mislabelled samples can help regulate sample extraction. We empirically evaluate our approach in a coral object dataset, collected via an Autonomous Underwater Vehicle (AUV) and human divers, that shows the benefit of incorporating extracted examples obtained from tracking. This work also demonstrates how controlling sample generation by tracking using a simple deep neural network can further improve an object detector.},
  label ={C89},
  category = {Conference Papers},
  pdf = "ICRA20_2542_FI.pdf",
  vid = "ICRA20_2542_VI_fi.mp4"
  }


@InProceedings{RahmanIROS2019b,
  author = 	 {Sharmin Rahman and Alberto {Quattrini Li} and Ioannis Rekleitis },
  title = 	 {Contour based Reconstruction of Underwater Structures Using Sonar, Visual, Inertial, and Depth Sensor },
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2019,
  doi  =         {https://doi.org/10.1109/iros40897.2019.8967697},
  pages = 	 {8048--8053},
  month = 	 {Nov.},
  address = 	 {Macau},
  abstract = {Abstract: This paper presents a systematic approach on realtime reconstruction of an underwater environment using Sonar,
Visual, Inertial, and Depth data. In particular, low lighting
conditions, or even complete absence of natural light inside
caves, results in strong lighting variations, e.g., the cone of the
artificial video light intersecting underwater structures, and the
shadow contours. The proposed method utilizes the well defined
edges between well lit areas and darkness to provide additional
features, resulting into a denser 3D point cloud than the usual
point clouds from a Visual SLAM system. Experimental results
in an underwater cave at Ginnie Springs, FL, with a custommade underwater sensor suite demonstrate the performance of
our system. This will enable more robust navigation of AUVs
using the denser 3D point cloud to detect obstacles and achieve
higher resolution reconstructions.},
  label ={C88},
  category = {Conference Papers},
  pdf = "IROS19_1537_FI.pdf",
  vid = "IROS19_1537_VI_fi.mp4"
}

@InProceedings{KarapetyanIROS2019,
  author = 	 {Nare Karapetyan and Adam Braude and Jason Moulton and Joshua A. Burstein and Scott White and Jason O'Kane and Ioannis Rekleitis},
  title = 	 {{Riverine Coverage with an Autonomous Surface Vehicle over Known Environments}},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2019,
  doi  =         {https://doi.org/10.1109/iros40897.2019.8968084},
  pages = 	 {3098--3104},
  month = 	 {Nov.},
  address = 	 {Macau},
  abstract = {Abstract: — Environmental monitoring and surveying
  operations on rivers currently are performed primarily with
  manually-operated boats. In this domain, autonomous coverage of
areas is of vital importance, for improving both the quality and
the efficiency of coverage. This paper leverages human expertise
in river exploration and data collection strategies to automate
and optimize these processes using autonomous surface vehicles
(ASVs). In particular, three deterministic algorithms for both
partial and complete coverage of a river segment are proposed,
providing varying path length, coverage density, and turning
patterns. These strategies resulted in increases in accuracy and
efficiency compared to human performance. The proposed
methods were extensively tested in simulation using maps of
real rivers of different shapes and sizes. In addition, to verify
their performance in real world operations, the algorithms were
deployed successfully on several parts of the Congaree River
in South Carolina, USA, resulting in total of more than 35km
of coverage trajectories in the field.},
  label ={C87},
  category = {Conference Papers},
  pdf = "IROS19_0502_FI.pdf",
  vid = "IROS19_0502_VI_fi.mp4"
}

@InProceedings{JoshiIROS2019,
  author = 	 {Bharat Joshi and Sharmin Rahman and Michail Kalaitzakis and Brennan Cain and James Johnson and Marios Xanthidis and Nare Karapetyan and Alan Hernandez and Alberto {Quattrini Li} and Nikolaos Vitzilaios and Ioannis Rekleitis},
  title = 	 {{Experimental Comparison of Open Source Visual-Inertial-Based State Estimation Algorithms in the Underwater Domain}},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2019,
  doi  =  {https://doi.org/10.1109/iros40897.2019.8968049},
  pages = 	 {7221--7227},
  month = 	 {Nov.},
  address = 	 {Macau},
  url = 	 {https://arxiv.org/abs/1904.02215},
  abstract = {Abstract: A plethora of state estimation techniques have
appeared in the last decade using visual data, and more recently
with added inertial data. Datasets typically used for evaluation
include indoor and urban environments, where supporting
videos have shown impressive performance. However, such techniques
have not been fully evaluated in challenging conditions,
such as the marine domain. In this paper, we compare ten recent
open-source packages to provide insights on their performance
and guidelines on addressing current challenges. Specifically,
we selected direct methods and tightly-coupled optimization
techniques that fuse camera and Inertial Measurement Unit
(IMU) data together. Experiments are conducted by testing all
packages on datasets collected over the years with underwater
robots in our laboratory. All the datasets are made available
online.},
  label ={C86},
  category = {Conference Papers},
  pdf = "IROS19_0500_FI.pdf",
  vid = "IROS19_0500_VI_fi.mp4"
}

@InProceedings{RahmanIROS2019a,
  author = 	 {Sharmin Rahman and Alberto {Quattrini Li} and Ioannis Rekleitis},
  title = 	 {{An Underwater SLAM System using Sonar, Visual, Inertial, and Depth Sensor}},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2019,
  doi  =  {https://doi.org/10.1109/iros40897.2019.8967703},
  pages = 	 {1861--1868},
  month = 	 {Nov.},
  address = 	 {Macau, (IROS ICROS Best Application Paper Award. Finalist)},
  abstract = {Abstract: This paper presents a novel tightly-coupled
keyframe-based Simultaneous Localization and Mapping
(SLAM) system with loop-closing and relocalization capabilities
targeted for the underwater domain.
Our previous work, SVIn, augmented the state-of-the-art
visual-inertial state estimation package OKVIS to accommodate
acoustic data from sonar in a non-linear optimization-based
framework. This paper addresses drift and loss of localization
– one of the main problems affecting other packages in underwater domain –
by providing the following main contributions:
a robust initialization method to refine scale using depth
measurements, a fast preprocessing step to enhance the image
quality, and a real-time loop-closing and relocalization method
using bag of words (BoW). An additional contribution is the
addition of depth measurements from a pressure sensor to the
tightly-coupled optimization formulation. Experimental results
on datasets collected with a custom-made underwater sensor
suite and an autonomous underwater vehicle from challenging underwater environments with poor visibility demonstrate
performance never achieved before in terms of accuracy and
robustness.},
  label ={C85},
  category = {Conference Papers},
  pdf = "IROS19_0269_FI.pdf",
  vid = "IROS19_0269_VI_fi.mp4"
}

@InProceedings{MoultonFSR2019,
  author = 	 {Jason Moulton and Nare Karapetyan and Michail Kalaitzakis and Alberto {Quattrini Li} and Nikolaos Vitzilaios and Ioannis Rekleitis},
  title = 	 {{Dynamic Autonomous Surface Vehicle Controls
Under Changing Environmental Forces}},
  booktitle = {12th Conference on Field and Service Robotics (FSR)},
  year = 	 2019,
  pages = 	 {(accepted)},
  month = 	 {Aug.},
  address = 	 {Tokyo, Japan},
  abstract = {Abstract: The ability to navigate, search, and monitor dynamic marine environments such as ports, deltas, tributaries, and rivers presents several challenges to both human operated and autonomously operated surface vehicles. Human data collection and monitoring is overly taxing and inconsistent when faced with large coverage areas, disturbed environments, and potentially uninhabitable situations. In contrast, the same missions become achievable with autonomous surface vehicles (ASV) configured and capable of accurately maneuvering in such environments. The two dynamic factors that present formidable challenges to completing precise maneuvers in coastal and moving waters are currents and winds. In this work, we present novel and inexpensive methods for sensing these external forces, together with methods for accurately controlling an ASV in the presence of such external forces. The resulting platform is capable of deploying bathymetric and water quality monitoring sensors. Experimental results in the local lakes and rivers demonstrate the feasibility of the proposed approach..},
  label ={C84},
  category = {Conference Papers},
  pdf = "FSR_2019_paper_46.pdf",
  vid = "FSR_2019_VA_46.mp4"
}

@InProceedings{ModasshirFSR2019,
  author = 	 {Md Modasshir and Sharmin Rahman and Ioannis Rekleitis},
  title = 	 {{Autonomous 3D Semantic Mapping of Coral Reefs}},
  booktitle = {12th Conference on Field and Service Robotics (FSR)},
  year = 	 2019,
  pages = 	 {(accepted)},
  month = 	 {Aug.},
  address = 	 {Tokyo, Japan},
  abstract = {Abstract: This paper presents the first-ever approach for autonomous 3D semantic mapping of coral reefs. The position of corals in 3D coordinates and the type of the coral are presented in such a3D semantic map, The intended application of this work is coral reef health monitoring, as the current assessment is based entirely on direct or indirect human observation. The proposed system joins a convolutional neural network (CNN) with a direct visual odometry approach and a correlation filter based tracker, Kernelized Correlation Filter (KCF), to identify the different coral species detected. In addition to the coral classification, the 3D position of each coral is identified producing a semantic map of the observed reef. Each coral is identified once and tracked to prevent a recount. The number of different coral species encountered in two separate traversed areas is reported. Furthermore, the shape and size of a coral can be extracted from the 3D reconstruction enabling the extraction of volumetric data for subsequent studies. Experimental results from the coral reefs of Barbados verify the robustness and accuracy of the proposed approach.},
  label ={C83},
  category = {Conference Papers},
  pdf = "FSR_2019_paper_45.pdf",
}

@InProceedings{KarapetyanFSR2019,
  author = 	 {Nare Karapetyan and Jason Moulton and Ioannis Rekleitis},
  title = 	 {{Meander Based River Coverage by an Autonomous Surface Vehicle}},
  booktitle = {12th Conference on Field and Service Robotics (FSR)},
  year = 	 2019,
  pages = 	 {(accepted)},
  month = 	 {Aug.},
  address = 	 {Tokyo, Japan},
  abstract = {Abstract: Autonomous coverage has tremendous importance for environmental surveying and exploration tasks performed on rivers both in terms of efficiency and data collection quality. Most surveys of rivers are performed manually using quite similar approaches. Using these practices to automate these processes improves the quality of survey operations. In addition to human expertise on the type of patterns, the coverage of a river can be optimized using the river meanders to determine the direction of coverage. In this work we use the implicit information on the speed of the water current, inferred from the curves of the river, to reduce the cost of coverage. We use autonomous surface vehicles (ASVs) to deploy the proposed methods and demonstrate the efficiency of our method. In addition we compare the proposed method with previous coverage techniques developed in our lab. When taking into account meanders the coverage time has been decreased in average by more than $20\%$. The deployments of the ASVs were performed on the Congaree River, SC, USA, and resulted in more than 27 km of total coverage trajectories},
  label ={C82},
  category = {Conference Papers},
  pdf = "FSR_2019_paper_44.pdf",
  vid = "FSR_2019_VA_44.mp4"
}


@InProceedings{ModasshirRobio2018,
  author =       {MD Modasshir and Sharmin Rahman and Oscar Youngquist and Ioannis Rekleitis},
  title =        {{Coral Identification and Counting with an Autonomous Underwater Vehicle}},
  booktitle = {IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  year =         2018,
  doi  =  {https://doi.org/10.1109/robio.2018.8664785},
  pages =        {524-- 529},
  month =        {Dec.},
  address =      {Kuala Lumpur, Malaysia, (Finalist of T. J. Tarn Best Paper in Robotics)},
 abstract = {Abstract: Monitoring coral reef populations as part of environmental assessment is essential. Recently, many marine science researchers are employing low-cost and power efficient Autonomous Underwater Vehicles (AUV) to survey coral reefs. While the counting problem, in general, has rich literature, little work has focused on estimating the density of coral population using AUVs. This paper proposes a novel approach to identify, count, and estimate coral populations. A Convolutional Neural Network (CNN) is utilized to detect and identify the different corals, and a tracking mechanism provides a total count for each coral species per transect. Experimental results from an Aqua2 underwater robot and a stereo hand\hyp held camera validate the proposed approach for different image qualities.},
  label ={C81},
  category = {Conference Papers},
  pdf = "Robio18.pdf",
  vid = "Robio18.mp4"
}


@InProceedings{MoultonISER2018,
  author =       {Jason Moulton and Nare Karapetyan and Alberto {Quattrini Li} and Ioannis Rekleitis},
  title =        {{External Force Field Modeling for Autonomous Surface Vehicles}},
  booktitle = {International Symposium on Experimental Robotics (ISER)},
  year =         2018,
  doi  =        {https://doi.org/10.1007/978-3-030-33950-0_29},
  month =        {Nov.},
  address =      {Buenos Aires, Argentina},
 abstract = {Abstract: Operating in the presence of strong adverse forces is a particularly challenging problem in field robotics. In most robotic operations where the robot is not firmly grounded, such as aerial, surface, and underwater, minimal external forces are assumed as the standard operating procedures. The first action for operating in the presence of non-trivial forces is modeling the forces and their effect on the robots motion. In this work an Autonomous Surface Vehicle (ASV), operating on lakes and rivers with varying winds and currents, collects wind and current measurements with an inexpensive custom-made sensor suite setup, and generates a model of the force field. The modeling process takes into account depth, wind, and current measurements along with the ASVs trajectory from GPS. In this work, we propose a method for an ASV to build an environmental force map by integrating in a Gaussian Process the wind, depth, and current measurements gathered at the surface. We run extensive experimental field trials for our approach on real Jetyak ASVs. Experimental results from different locations validate the proposed modeling approach.},
  label ={C80},
  category = {Conference Papers},
  pdf = "MoultonISER2018.pdf",
  vid = "MoultonISER2018.mp4"
}

@inProceedings{AmigoniDARS2019,
  title={Online Update of Communication Maps for Exploring Multirobot Systems Under Connectivity Constraints},
  author={Amigoni, Francesco and Banfi, Jacopo and Basilico, Nicola and Rekleitis, Ioannis and {Quattrini Li}, Alberto },
  booktitle={Distributed Autonomous Robotic Systems},
  pages={513--526},
  year={2018},
  doi  =  {https://doi.org/10.1007/978-3-030-05816-6_36},
  month =        {Oct.},
  publisher={Springer},
  abstract = {Abstract: Multirobot systems for exploring initially unknown environments are often subject to communication constraints, due to the limited range of their transmission devices and to mission requirements. In order to make decisions about where the robots should move, a communication map that encodes knowledge of the locations from which communication is possible is usually employed. Typically, simple line of sight or circle communication models (that are rather independent of the specific environment in which the exploration is carried out) are considered. In this paper, we make a step forward and present a multirobot system that learns and updates a communication map during the exploration mission. In particular, we propose methods to incrementally update vertices, corresponding to the locations visited by robots, and edges, corresponding to communication links, of a graph according to the measured power of radio-frequency signals and to the predictions made by a model based on Gaussian Processes. Experimental results obtained in simulation show that the proposed methods build and update rich communication maps specific for the environments being visited and that the availability of these maps can improve the exploration performance. },
  label ={C79},
  category = {Conference Papers},
  pdf = "AmigoniDARS2018.pdf",
  vid = "AmigoniDARS2018.mp4"
}

@InProceedings{DamronIROS2018,
  author =       {Hunter Damron and Alberto Quattrini Li and Ioannis Rekleitis},
  title =        {{Underwater Surveying via Bearing only Cooperative Localization}},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year =         2018,
  doi  =  {https://doi.org/10.1109/iros.2018.8593431},
  pages =        {3957-3963},
  month =        {Oct.},
  address =      {Madrid, Spain},
 abstract = {Abstract: Bearing only cooperative localization has been used successfully on aerial and ground vehicles. In this paper we present an extension of the approach to the underwater domain. The focus is on adapting the technique to handle the challenging visibility conditions underwater. Furthermore, data from inertial, magnetic, and depth sensors are utilized to improve the robustness of the estimation. In addition to robotic applications, the presented technique can be used for cave mapping and for marine archeology surveying, both by human divers. Experimental results from different environments, including a fresh water, low visibility, lake in South Carolina; a cavern in Florida; and coral reefs in Barbados during the day and during the night, validate the robustness and the accuracy of the proposed approach.},
  label ={C78},
  category = {Conference Papers},
  pdf = "DamronIROS2018.pdf",
  vid = "IROS18.mp4"
}

@InProceedings{RahmanICRA2018,
  author = 	 {Sharmin Rahman and Alberto Quattrini Li and Ioannis Rekleitis},
  title = 	 {{Sonar Visual Inertial SLAM of Underwater Structures}},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = 	 2018,
  doi  =  {https://doi.org/10.1109/icra.2018.8460545},
  pages = 	 {5190--5196},
  month = 	 {May},
  address = 	 {Brisbane, Australia},
abstract = {Abstract: This paper presents an extension to a state of
the art Visual-Inertial state estimation package (OKVIS) in
order to accommodate data from an underwater acoustic
sensor. Mapping underwater structures is important in several
fields, such as marine archaeology, search and rescue, resource
management, hydrogeology, and speleology. Collecting the data,
however, is a challenging, dangerous, and exhausting task. The
underwater domain presents unique challenges in the quality of
the visual data available; as such, augmenting the exteroceptive
sensing with acoustic range data results in improved reconstructions
of the underwater structures. Experimental results from
underwater wrecks, an underwater cave, and a submerged bus
demonstrate the performance of our approach.},
  label ={C77},
  category = {Conference Papers},
  pdf = "RahmanICRA2018.pdf",
  vid = "ICRA18_1211_VI.mp4"
  }

@InProceedings{ManjannaICRA2018,
  author = 	 {Sandeep Manjanna and Alberto {Quattrini Li} and Ryan N. Smith and Ioannis Rekleitis and Gregory Dudek},
  title = 	 {{Heterogeneous Multirobot System for Exploration and Strategic Water Sampling}},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = 	 2018,
  doi  =  {https://doi.org/10.1109/icra.2018.8460759},
  pages = 	 {4873--4880},
  month = 	 {May},
  address = 	 {Brisbane, Australia},
abstract = {Abstract: Physical sampling of water for off-site analysis is
necessary for many applications like monitoring the quality of
drinking water in reservoirs, understanding marine ecosystems,
and measuring contamination levels in fresh-water systems. In
this paper, the focus is on algorithms for efficient measurement
and sampling using a multi-robot, data-driven, water-sampling
behavior, where autonomous surface vehicles plan and execute
water sampling using the chlorophyll density as a cue for
plankton-rich water samples. We use two Autonomous Surface
Vehicles (ASVs), one equipped with a water quality sensor and
the other equipped with a water-sampling apparatus. The ASV
with the sensor acts as an explorer, measuring and building a
spatial map of chlorophyll density in the given region of interest.
The ASV equipped with the water sampling apparatus makes
decisions in real time on where to sample the water based on
the suggestions made by the explorer robot.
We evaluate the system in the context of measuring chlorophyll
distributions. We do this both in simulation based on
real geophysical data from MODIS measurements, and on real
robots in a water reservoir. We demonstrate the effectiveness
of the proposed approach in several ways including in terms of
mean error in the interpolated data as a function of distance
traveled.},
  label ={C76},
  category = {Conference Papers},
  pdf = "ManjannaICRA2018.pdf",
  vid = "ICRA18_1372_VI.mp4"
  }

@InProceedings{KarapetyanICRA2018,
  author = 	 {Nare Karapetyan and Jason Moulton and Jeremy Lewis and Alberto {Quattrini Li} and Jason O'Kane and Ioannis Rekleitis},
  title = 	 {{Multi-robot Dubins Coverage with Autonomous Surface Vehicles}},
  booktitle = {IEEE International Conference on Robotics and Automation},
  year = 	 2018,
  doi  =   {https://doi.org/10.1109/icra.2018.8460661},
  pages = 	 {2373--2379},
  month = 	 {May},
  address = 	 {Brisbane, Australia},
abstract = {Abstract:In large scale coverage operations, such as marine
exploration or aerial monitoring, single robot approaches are
not ideal, as they may take too long to cover a large area. In such
scenarios, multi-robot approaches are preferable. Furthermore,
several real world vehicles are non-holonomic, but can be
modeled using Dubins vehicle kinematics. This paper focuses
on environmental monitoring of aquatic environments using
Autonomous Surface Vehicles (ASVs). In particular, we propose
a novel approach for solving the problem of complete coverage
of a known environment by a multi-robot team consisting of
Dubins vehicles. It is worth noting that both multi-robot coverage
and Dubins vehicle coverage are NP-complete problems.
As such, we present two heuristics methods based on a variant
of the traveling salesman problem—k-TSP—formulation and
clustering algorithms that efficiently solve the problem. The
proposed methods are tested both in simulations to assess their
scalability and with a team of ASVs operating on a 200 km2
lake to ensure their applicability in real world.},
  label ={C75},
  category = {Conference Papers},
  pdf = "KarapetyanICRA2018.pdf",
  vid = "ICRA18_1150_VI.mp4"
  }
  
@InProceedings{ModasshirCRV2018,
  author = {MD Modasshir and Alberto Quattrini Li and Ioannis Rekleitis},
  title = {Deep Neural Networks: a Comparison on Different Computing Platforms},
 booktitle = {Canadian Conference on Computer and Robot Vision (CRV)},
   year = 	 2018,
   doi  =  {https://doi.org/10.1109/crv.2018.00060},
  pages = 	 {383--389},
  month = 	 {May},
 address = 	 {Toronto, ON, Canada},
 abstract = {Abstract: Deep Neural Networks (DNN) have gained tremendous popularity over the last years for several computer vision tasks, including classification and object detection. Such techniques have been able to achieve human-level performance in many tasks and have produced results of unprecedented accuracy. As DNNs have intense computational requirements in the majority of applications, they utilize a cluster of computers or a cutting edge Graphical Processing Unit (GPU), often having excessive power consumption and generating a lot of heat. In many robotics applications the above requirements prove to be a challenge, as there is limited power on-board and heat dissipation is always a problem. In particular in underwater robotics with limited space, the above two requirements have been proven prohibitive. As first of this kind, this paper aims at analyzing and comparing the performance of several stateof-the-art DNNs on different platforms. With a focus on the underwater domain, the capabilities of the Jetson TX2 from NVIDIA and the Neural Compute Stick from Intel are of particular interest. Experiments on standard datasets show how different platforms are usable on an actual robotic system, providing insights on the current state-of-the-art embedded systems. Based on such results, we propose some guidelines in choosing the appropriate platform and network architecture for a robotic system.},
  label ={C74},
  category = {Conference Papers},
  pdf = "ModasshirCRV2018.pdf",
}

@InProceedings{PenumarthiMRS2017,
  author       = {Phani Krishna Penumarthi and Alberto Quattrini Li and Jacopo Banfi and Nicola Basilico and Francesco Amigoni and Ioannis Rekleitis and Jason M. O'Kane and Srihari Nelakuditi},
  title        = {Multirobot Exploration for Building Communication Maps with Prior from Communication Models},
  booktitle    = {International Symposium on Multi-Robot and Multi-Agent Systems},
  month        = {Dec.},
  pages = 	 {90--96},
  address      = {Los Angeles, CA, USA},
  year	       = {2017},
  doi  =  {https://doi.org/10.1109/mrs.2017.8250936},
  abstract = {Abstract: This paper addresses the problem of building a communication map of a known environment using multiple robots. A communication map encodes whether two robots are likely to be able to communicate between two arbitrary loca- tions. Such a communication map is fundamental for reliably deploying a multirobot system to accomplish a variety of tasks, including exploration and environmental monitoring. Previous work proposed offline approaches, which did not utilize data measured by robots. This paper, utilizing Gaussian Processes, proposes methods to efficiently build a communication map with multiple robots. Specifically, the number of measurements used to update the communication map, and the number of possible candidate locations where robots should go are reduced, by exploiting communication models that can be built from the physical map of the environment. This allows robots to take fewer measurements, travel less distance, be more efficient in processing the data online, and get similar accuracy to methods that consider all the locations in the environment. Experiments with a team of TurtleBot 2 platforms validate the approach.},
  label ={C73},
  category = {Conference Papers},
  pdf = "MRS17_01.pdf",
  vid = "MRS17_01_VI.mp4"
}


@InProceedings{KarapetyanIROS2017,
  author = 	 {Nare Karapetyan and Kelly Benson and Chris McKinney and Perouz Taslakian and Ioannis Rekleitis},
  title = 	 {Efficient Multi-Robot Coverage of a Known Environment},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2017,
  pages = 	 {1846 - 1852},
  month = 	 {Sep.},
  address = 	 {Vancouver, BC, Canada},
  abstract = {Abstract: This paper addresses the complete area coverage problem of
a known environment by multiple-robots. Complete area
coverage is the problem of moving an end-effector over all
available space while avoiding existing obstacles. In such
tasks, using multiple robots can increase the efficiency of
the area coverage in terms of minimizing the operational
time and increase the robustness in the face of robot
attrition. Unfortunately, the problem of finding an optimal
solution for such an area coverage problem with multiple
robots is known to be NP-complete. In this paper we present
two approximation heuristics for solving the multi-robot
coverage problem. The first solution presented is a direct
extension of an efficient single robot area coverage
algorithm, based on an exact cellular decomposition. The
second algorithm is a greedy approach that divides the area
into equal regions and applies an efficient single-robot
coverage algorithm to each region. We present experimental
results for two algorithms. Results indicate that our
approaches provide good coverage distribution between
robots and minimize the workload per robot, meanwhile
ensuring complete coverage of the area.},
  label ={C72},
  category = {Conference Papers},
  pdf = "IROS2017b.pdf",
  vid = "IROS2017b.mp4"
}

@InProceedings{LewisIROS2017,
 author = 	 {Jeremy Lewis and William Edwards and Kelly Benson and Ioannis Rekleitis and Jason O'Kane},
  title = 	 {Semi-Boustrophedon Coverage with a Dubins Vehicle  },
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2017,
  pages = 	 {5630 - 5637},
  month = 	 {Sep.},
  address = 	 {Vancouver, BC, Canada},
  abstract = {Abstract: This paper addresses the problem of generating coverage
paths---that is, paths that pass within some sensor
footprint of every point in an environment---for vehicles
with Dubins motion constraints. We extend previous work
that solves this coverage problem as a traveling salesman
problem (TSP) by introducing a practical heuristic
algorithm to reduce runtime while maintaining near-optimal
path length. Furthermore, we show that generating an
optimal coverage path is NP-hard by reducing from the Exact
Cover problem, which provides justification for our
algorithm's conversion of Dubins coverage instances to TSP
instances. Extensive experiments demonstrate that the
algorithm does indeed produce length paths comparable to
optimal in significantly less time.},
  label ={C71},
  category = {Conference Papers},
  pdf = "IROS2017a.pdf",
  vid = "IROS2017a.mp4"
}

@INPROCEEDINGS{HoodICUAS2017, 
author={Shannon Hood and Kelly Benson and Pattric Hamod and Daniel Madison and Jason M. O'Kane and Ioannis Rekleitis}, 
booktitle={International Conference on Unmanned Aircraft Systems (ICUAS)}, 
title={Bird's eye view: Cooperative exploration by UGV and UAV}, 
year={2017}, 
pages={247-255}, 
keywords={Cameras;Collaboration;Robot kinematics;Simultaneous localization and mapping;Unmanned aerial vehicles}, 
doi={10.1109/ICUAS.2017.7991513},
address = 	 {Miami, FL, USA},
month={Jun.},
abstract = {Abstract: This paper proposes a solution to the problem of cooperative exploration using an Unmanned Ground Vehicle (UGV) and an Unmanned Aerial Vehicle (UAV). More specifically, the UGV navigates through the free space, and the UAV provides enhanced situational awareness via its higher vantage point. The motivating application is search and rescue in a damaged building. A camera atop the UGV is used to track a fiducial tag on the underside of the UAV, allowing the UAV to maintain a fixed pose relative to the UGV. Furthermore, the UAV uses its front facing camera to provide a birds-eye-view to the remote operator, allowing for observation beyond obstacles that obscure the UGV's sensors. The proposed approach has been tested using a TurtleBot 2 equipped with a Hokuyo laser ranger finder and a Parrot Bebop 2. Experimental results demonstrate the feasibility of this approach. This work is based on several open source packages and the generated code is available on-line.},
  label ={C70},
  category = {Conference Papers},
  pdf = "ICUAS2017.pdf",
}

@InProceedings{BanfiICRA2017,
  author = 	 {Jacopo Banfi and Alberto Quattrini Li and Nicola Basilico and Ioannis Rekleitis and Francesco Amigoni},
  title = 	 {{Multirobot Online Construction of Communication Maps}},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  year = 	 2017,
  pages = 	 {2577 - 2583},
  month = 	 {May},
  address = 	 {Singapore},
abstract = {Abstract: The importance of communication in many mul- tirobot information-gathering tasks requires the availability of reliable communication maps. These provide estimates of the radio signal strength and can be used to predict the presence of communication links between different locations of the environment. In the problem we consider, a team of mobile robots has to build such maps autonomously in a robot-to-robot communication setting. The solution we propose models the signal’s distribution with a Gaussian Process and exploits different online sensing strategies to coordinate and guide the robots during their data acquisition. Our methods show interesting operative insights both in simulations and on real TurtleBot 2 platforms.},
  label ={C69},
  category = {Conference Papers},
  pdf = "ICRA17_2161_FI.pdf",
  vid = "ICRA17_2161_VI_fi.mp4"
  }

@InProceedings{WeidnerICRA2017,
  author = 	 {Nicholas Weidner and Sharmin Rahman and Alberto Quattrini Li and Ioannis Rekleitis},
  title = 	 {Underwater Cave Mapping using Stereo Vision},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  year = 	 2017,
  pages = 	 {5709 - 5715},
  month = 	 {May},
  address = 	 {Singapore},
  abstract = {Abstract: This paper presents a systematic approach for the 3-D mapping of underwater caves. Exploration of underwater caves is very important for furthering our understanding of hydrogeology, managing efficiently water resources, and advancing our knowledge in marine archaeology. Underwater cave exploration by human divers however, is a tedious, labor intensive, extremely dangerous operation, and requires highly skilled people. As such, it is an excellent fit for robotic technology, which has never before been addressed. In addition to the underwater vision constraints, cave mapping presents extra challenges in the form of lack of natural illumination and harsh contrasts, resulting in failure for most of the state-of- the-art visual based state estimation packages. A new approach employing a stereo camera and a video-light is presented. Our approach utilizes the intersection of the cone of the video-light with the cave boundaries: walls, floor, and ceiling, resulting in the construction of a wire frame outline of the cave. Successive frames are combined using a state of the art visual odometry algorithm while simultaneously inferring scale through the stereo reconstruction. Results from experiments at a cave, part of the Sistema Camilo, Quintana Roo, Mexico, validate our approach. The cave wall reconstruction presented provides an immersive experience in 3-D.},
  label ={C68},
  category = {Conference Papers},
  pdf = "ICRA17_2576_FI.pdf",
  vid = "ICRA17_2576_VI_fi.mp4"
}

@InProceedings{ManjannaCRV2017,
  author = {Sandeep Manjanna and Johanna Hansen and Alberto Quattrini Li and Ioannis Rekleitis and Gregory Dudek},
  title = {Collaborative Sampling Using Heterogeneous Marine Robots Driven by Visual Cues},
 booktitle = {Canadian Conference on Computer and Robot Vision (CRV)},
   year = 	 2017,
  pages = 	 {87-94},
  month = 	 {May},
 address = 	 {Edmonton, AB, Canada},
 abstract = {Abstract: This paper addresses distributed data sampling
in marine environments using robotic devices. We present
a method to strategically sample locally observable features
using two classes of sensor platforms. Our system consists
of a sophisticated autonomous surface vehicle (ASV) which
strategically samples based on information provided by a
team of inexpensive sensor nodes. The sensor nodes effectively
extend the observational capabilities of the vehicle by capturing
georeferenced samples from disparate and moving points across
the region. The ASV uses this information, along with its own
observations, to plan a path so as to sample points which
it expects to be particularly informative. We compare our
approach to a traditional exhaustive survey approach and show
that we are able to effectively represent a region with less
energy expenditure. Experiments in simulation and using the
real vehicles validate our approach.},
  label ={C67},
  category = {Conference Papers},
  pdf = "CRV2017.pdf",
}



@InProceedings{QuattriniLiIROS2016,
  author = 	 {Alberto {Quattrini Li} and Marios Xanthidis and Jason O'Kane and Ioannis Rekleitis},
  title = 	 {Active Localization with Dynamic Obstacles},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2016,
  month = 	 {Oct.},
  address = 	 {Daejeon, Korea},
  abstract = {Abstract: This paper addresses the problem of robot global localization in a known environment, in the presence of many dynamic obstacles. Deploying a robot in crowded spaces such as museums, shopping malls, department stores, or university campuses is especially challenging because the moving people occlude the static parts of the environment, such as walls and doorways, making the robot essentially blind. A new weighting function is proposed for a particle filter state estimation algorithm that accounts for the presence of dynamic obstacles and avoids population depletion. An active localization strategy is employed which guides the robot to locations that resolve ambiguities and eliminate hypotheses in a systematic manner. Experimental results from multiple simulations and from real robot deployments validate the localization improvements achieved by the proposed method.},
  label ={C66},
  category = {Conference Papers},
  pdf = "RekleitisIROS2016.pdf",
  vid = "IROS16_0115_VI_i.mp4"
  }



@InProceedings{QuattriniLiISERVO2016,
  author = 	 {Alberto {Quattrini Li} and Adem Coskun and Sean M. Doherty and Shervin Ghasemlou and Apoorv S. Jagtap and MD Modasshir and Sharmin Rahman and Akanksha  Singh and Marios Xanthidis and Jason M. O'Kane and  Ioannis Rekleitis },
  title = 	 {Experimental Comparison of open source Vision based State Estimation Algorithms},
  booktitle = {International Symposium of Experimental Robotics (ISER)},
  year = 	 2016,
  month = 	 {Mar.},
  address = 	 {Tokyo, Japan},
  abstract = {Abstract: The problem of state estimation using primarily visual data has received a lot of attention in the last decade. Several open source packages have appeared addressing the problem, each supported by im- pressive demonstrations. Applying any of these packages on a new dataset however, has been proven extremely challenging. Suboptimal perfor- mance, loss of localization, and challenges in customization have not produced a clear winner. Several other research groups have presented superb performance without releasing the code, sometimes materializing as commercial products. In this paper, ten of the most promising open source packages are evaluated, by cross validating them on the datasets provided for each package and by testing them on eight different datasets collected over the years in our laboratory. Indoor and outdoor, terrestrial and flying vehicles, in addition to underwater robots, cameras, and buoys were used to collect data. An analysis on the motions required for the different approaches and an evaluation of their performance is presented.
},
  label ={C65},
  category = {Conference Papers},
  pdf = "RekleitisISERVO2016.pdf"
}

@InProceedings{QuattriniLiISERMulti2016,
  author = 	 {Alberto {Quattrini Li} and Ioannis Rekleitis and Sandeep Manjanna and Nikhil Kakodkar and Johanna Hansen and Gregory Dudek and Leonardo Bobadilla and Jacob Anderson and Ryan N. Smith},
  title = 	 {Data Correlation and Comparison from Multiple Sensors over a Coral Reef with a Team of Heterogeneous Aquatic Robots},
  booktitle = {International Symposium of Experimental Robotics (ISER)},
  year = 	 2016,
  month = 	 {Mar.},
  address = 	 {Tokyo, Japan},
  abstract = {Abstract: This paper presents experimental insights from the deployment of an ensemble of heterogeneous autonomous sensor systems over a shallow coral reef. Visual, inertial, GPS, and ultrasonic data collected are compared and correlated to produce a comprehensive view of the health of the coral reef. Coverage strategies are discussed with a focus on the use of informed decisions to maximize the information collected during a fixed period of time.},
  label ={C64},
  category = {Conference Papers},
  pdf = "RekleitisISERMulti2016.pdf"
}

@InProceedings{XanthidisMed2016,
  author = 	 {Marios Xanthidis and Kostantinos J. Kyriakopoulos and Ioannis Rekleitis},
  title = 	 {Dynamically Efficient Kinematics for Hyper-Redundant Manipulators},
  booktitle = {The 24th Mediterranean Conference on Control and Automation (MED)},
  year = 	 2016,
  pages = 	 {207-213},
  month = 	 {Jun.},
  address = 	 {Athens, Greece},
  abstract = {Abstract: A hyper-redundant robotic arm is a manipulator with many degrees of freedom, capable of executing tasks in cluttered environments where robotic arms with fewer degrees of freedom are unable to operate. This paper introduces a new method for modeling those manipulators in a completely dynamic way. The proposed method enables online changes of the kinematic structure with the use of a special function; termed “meta-controlling function”. This function can be used to develop policies to reduce drastically the computational cost for a single task, and to robustly control the robotic arm, even in the event of partial damage. The direct and inverse kinematics are solved for a generic three-dimensional articulated hyper- redundant arm, that can be used as a proof of concept for more specific structures. To demonstrate the robustness of our method, experimental simulation results, for a basic “meta- controlling” function, are presented.},
label ={C63},
category = {Conference Papers},
pdf = "RekleitisMed2016.pdf"}

@INPROCEEDINGS{BanfiICRA2016, 
author={Jacopo Banfi and Alberto Quattrini Li and Nicola Basilico and Ioannis Rekleitis and Francesco Amigoni}, 
booktitle={IEEE International Conference on Robotics and Automation (ICRA)}, 
title={Asynchronous multirobot exploration under recurrent connectivity constraints}, 
year={2016}, 
pages={5491-5498}, 
keywords={multi-robot systems;path planning;asynchronous multirobot exploration;centralized asynchronous planning framework;centralized control;communication constraints;recurrent connectivity constraints;team exploration strategy;Base stations;Planning;Relays;Robot kinematics;Robot sensing systems}, 
doi={10.1109/ICRA.2016.7487763},
address = 	 {Stockholm, Sweden},
month={May},
abstract = {Abstract: In multirobot exploration under centralized control, communication plays an important role in constraining the team exploration strategy. Recurrent connectivity is a way to define communication constraints for which robots must connect to a base station only when making new observations. This paper studies effective multirobot exploration strategies under recurrent connectivity by considering a centralized and asynchronous planning framework. We formalize the problem of selecting the optimal set of locations robots should reach, provide an exact formulation to solve it, and devise an approximation algorithm to obtain efficient solutions with a bounded loss of optimality. Experiments in simulation and on real robots evaluate our approach in a number of settings.},
label ={C62},
category = {Conference Papers},
pdf = "RekleitisICRA2016.pdf",
vid="1735_VI.mp4"
}

@InProceedings{WuHFES2015,
  author = 	 {Xian Wu and Rachel E. Stuck and Ioannis Rekleitis and Jenay M Beer},
  title = 	 {Towards a Framework for Human Factors in Underwater Robotics},
  booktitle = {Human Factors and Ergonomics Society International Annual Meeting},
  year = 	 2015,
  volume = 	 59,
  pages = 	 {1115-1119},
  address= {Los Angeles, CA, USA},
  month = 	 {Sep.},
abstract = {Abstract: This paper presents a study identifying the human-, robot-, task-, and environmental-related factors that impact the feasibility and usability of semi Autonomous Underwater Vehicles (sAUVs) from a human factors perspective. A multi-method approach was utilized. First, a subject matter expert (SME) interview was used to analyze video data of operators interacting with sAUVs. The results suggest considerations for the capabilities and limitations of the human and robot, in relation to the dynamic demands of the task and environment. A preliminary human factors conceptual model to depict and categorize these components was proposed. Next, a questionnaire was administered to sAUV roboticists (N=15) that assessed their perceptions related to the level of challenge associated to each of the factors identified in the model. The data suggest that all of the factors identified in our conceptual model are, in fact, challenging. In particular, our data suggest that situation awareness, communication, task complexity, visibility, and the robot’s user interface were some of the most challenging variables in sUAV operation.},
label ={C61},
category = {Conference Papers},
pdf = "RekleitisHFES2015.pdf"
}

@InProceedings{RezanejadIROS2015,
  author = 	 {Morteza Rezanejad and Babak Samari and Ioannis Rekleitis and Kaleem Siddiqi and Gregory Dudek},
  title = 	 {Robust Environment Mapping Using Flux Skeletons},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2015,
  pages = 	 {5700-5705},
  month = 	 {Sep.},
  address = 	 {Hamburg, Germany},
  abstract = {Abstract: We consider how to directly extract a road map (also known as a topological representation) of an initiallyunknown 2-dimensional environment via an on-line procedure which robustly computes a retraction of its boundaries. While such approaches are well known for their theoretical elegance, computing such representations in practice is complicated when the data is sparse and noisy. In this paper we present the online construction of a topological map and the implementation of a control law for guiding the robot to the nearest unexplored area. The proposed method operates by allowing the robot to localize itself on a partially constructed map, calculate a path to unexplored parts of the environment (frontiers), compute a robust terminating condition when the robot has fully explored the environment, and achieve loop closure detection. The proposed algorithm results in smooth safe paths for the robot’s navigation needs. The presented approach is an any-time-algorithm which allows for the active creation of topological maps from laserscan data, as it is being acquired. The resulting map is stable under variations to noise and the initial conditions. The key idea is the use of a flux-based skeletonization algorithm on the latest occupancy grid map. We also propose a navigation strategy based on a heuristic where the robot is directed towards nodes in the topological map that open to empty space. The method is evaluated on both synthetic data and in the context of active exploration using a Turtlebot 2. Our results demonstrate complete mapping of different environments with smooth topological abstraction without spurious edges.},
 category = {Conference Papers},
 label ={C60},
  pdf = "RekleitisIROS2015.pdf"
}

@InProceedings{BoydstunCRV2015,
  author = 	 {Daniel Boydstun and Matthew Farich and John McCarthy III and Silas Rubinson and Zachary Smith and Ioannis Rekleitis},
  title = 	 {Drifter Sensor Network for Environmental Monitoring},
  booktitle = {Canadian Conference on Computer Robot Vision (CRV)},
  year = 	 2015,
  pages = 	 {16-22},
  month = 	 {Jun.},
  address = 	 {Halifax, NS, Canada},
  abstract = {Abstract: This paper presents the design, development, and deployment of a sensor network of drifter nodes. The target domain is coastal water monitoring, and study of Lagrangian water dynamics. The nodes are equipped with a camera, inertial measurement unit (IMU), GPS, WiFi, and a computing unit. Each unit is water resistant, with buoyancy characteristics that enable it to float in a vertical position. The sensors are capable of recording geolocated visual data at variable rates. They collect Lagrangian current observations as they move along the water surface. In addition to the current measurements, the drifters are also recording image data that provide insights about the health of the marine life below the surface. We propose, to utilize the motion generated by the wave action in order to record wider field of view images from the ocean floor. Results from a successful deployment of the coast of Barbados are presented together with a discussion on lessons learned.},
category = {Conference Papers},
label ={C59},
pdf = "CRV2015b.pdf"
}



@InProceedings{ZhangCRV2015,
  author = 	 {Qiwen Zhang and Ioannis Rekleitis and Gregory Dudek},
  title = 	 {Uncertainty Reduction via Heuristic Search Planning on Hybrid Metric/Topological Map},
  booktitle = {Canadian Conference on Computer Robot Vision (CRV)},
  year = 	 2015,
  pages = 	 {222-229},
    month = 	 {Jun.},
  address = 	 {Halifax, NS, Canada},
abstract = {Abstract: This paper presents an extension of our previous work on hybrid metric/topological maps to enable uncertainty reduction planning through the map, taking into account both map uncertainty and distance. An enhancement of the edge structure which enables the simulation of bidirectional edge propagation through an extended Kalman filter is proposed in our heuristic search planning algorithm to plan for maximal map uncertainty reduction. This work expands on the heuristic search framework proposed in [1] to apply in hybrid metric/topological maps instead of more constrained camera sensor networks. Experimental results from realistic simulations and deployment on a real robotic system are presented to show the efficacy of the proposed algorithm and validate our approach for uncertainty reduction.},
category = {Conference Papers},
label ={C58},
pdf = "CRV2015a.pdf"
}


@INPROCEEDINGS{ZhangIROS2014, 
author={Qiwen Zhang and Whitney, D. and Shkurti, F. and Rekleitis, I.}, 
booktitle={IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
title={Ear-based exploration on hybrid metric/topological maps}, 
year={2014}, 
month={Sep.}, 
pages={3081-3088},
address={Chicago, IL, USA},
keywords={Kalman filters;computational geometry;graph theory;mobile robots;nonlinear filters;ear-based exploration;extended Kalman filter;generalized Voronoi graph;hybrid metric/topological maps;indoor environments;loop closure;mobile robot;topological graph;Image edge detection;Lasers;Measurement;Navigation;Robot sensing systems;Uncertainty}, 
doi={10.1109/IROS.2014.6942988},
abstract = {Abstract: In this paper we propose a hierarchy of techniques for performing loop closure in indoor environments together with an exploration strategy designed to reduce uncertainty in the resulting map. We use the generalized Voronoi graph to represent the indoor environment and an extended Kalman filter to track the pose of the robot and the position of the junctions (vertices) of the topological graph. Every time a vertex is revisited, the robot re-localizes and updates the uncertainty estimate accordingly. Finally, since the reduction of the map uncertainty remains one of the main concerns, the robot will optimize its schedule of revisiting junctions in the environment in order to reduce the accumulated uncertainty. Experimental results from a mobile robot equipped with a laser range-finder and results from realistic simulations that validate our approach are presented.},
category = {Conference Papers},
label ={C57},
pdf = "Rekleitis_IROS2014.pdf",
vid = "1018_VI.mp4"
}

@InProceedings{DugasISRR2013,
  author = 	 {Olivier Dugas and Philippe Giguere and Ioannis Rekleitis},
  title = 	 {{6DoF Camera Localization for Mutually Observing Robots}},
  booktitle = {International Symposium on Robotics Research (ISRR)},
  year = 	 2013,
  month = 	 {Dec.},
  address = 	 {Singapore},
  abstract = {Abstract: The solution of cooperative localization is of particular importance to teams of aerial or underwater robots operating in areas devoid of landmarks. The problem becomes harder if the localization system must be low-cost and lightweight enough that only consumer-grade cameras can be used. This paper presents an analytical solution to the six degrees of freedom cooperative localization problem using bearing only measurements. Given two mutually observing robots, each one equipped with a camera and two markers, and given that they each take a picture at the same moment, we can recover the coordinate transformation that expresses the pose of one robot in the frame of reference of the other. The novelty of our approach is the use of two pairs of bearing measurements for the pose estimation instead of using both bearing and range measurements. The accuracy of the results is verified in extensive simulations and in experiments with real hardware. At 6.5 m distance, position was estimated with a mean error between 0.021 m and 0.025 m and orientation was recovered with a mean error between 0.019 rad and 0.037 rad. This makes our solution particularly well suited for deployment on fleets of inexpensive robots moving in 6 DoF such as blimps.},
 category = {Conference Papers},
 label ={C56},
  pdf = "Rekleitis_ISRR2013.pdf"
  }



@InProceedings{RekleitisRobio2013,
  author = 	 {Ioannis Rekleitis},
  title = 	 {{Multi-Robot Simultaneous Localization and Uncertainty Reduction on Maps (MR-SLURM)}},
  booktitle = {IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  year = 	 2013,
  pages = 	 {1216-1221},
  month = 	 {Dec.},
  address = 	 {Shenzhen, China},
  abstract = {Abstract: This paper presents two strategies for simultaneous localization and uncertainty reduction on maps for a team of robots. The proposed strategies differentiate between homogeneous and heterogeneous multi-robot teams assigning different roles based on risk and/or capabilities. We apply the proposed algorithms to the Robot-Camera Sensor Network localization problem, where a team of robots moves through an environment equipped with a camera sensor network. Each robot uses its own pose estimate to localize every camera it encounters. This is achieved by using the camera observation of the robot to extract a 6-DoF transformation between the camera and the robot. The inverted transformation places the camera in the robots global frame of reference, and map merging among the multiple robots places the cameras and the team of robots in a common frame of reference. At the core of the estimation, an extended Kalman filter algorithm is used to estimate the joint pose of robots and cameras. Experimental results from realistic simulations are presented that validate the proposed strategies.},
  category = {Conference Papers},
label ={C55},
  pdf = "Rekleitis_ROBIO2013.pdf"
}

@InProceedings{RekleitisRobio2012,
  author = 	 {Ioannis Rekleitis},
  title = 	 {Simultaneous Localization and Uncertainty Reduction on Maps (SLURM): Ear based Exploration},
  booktitle = {IEEE International Conference on Robotics and Biomimetics (ROBIO)},
  pages = 	 {501--507},
  year = 	 2012,
  address = 	 {Guangzhou, China},
  month = 	 {Dec.},
  abstract = {Abstract: Efficient exploration and accurate mapping are two conflicting goals. Efficient exploration requires minimizing traversal of previously mapped territory, accurate mapping necessitates that the robot goes through previously mapped areas to reduce the accumulated uncertainty. This problem has many parallels with the exploration versus exploitation problem. In this paper a new algorithm is proposed that explicitly aims to facilitate loop closure in a systematic way. The problem of localizing a camera sensor network by employing a mobile robot will be used to demonstrate the effect that different parameters of the ear-based exploration strategy have on the speed of exploration and the accumulated uncertainty.  Simulation results using a realistic noise model are presented for different environments.},
category = {Conference Papers},
  label ={C54},
  pdf = "Rekleitis_ROBIO2012.pdf"
}

@InProceedings{GiguereIROS2012,
  author = 	 {Philippe Giguere and Ioannis Rekleitis and Maxime Latulippe},
  title = 	 {{I see you, you see me: Cooperative Localization through Bearing-Only Mutually Observing Robots}},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages = 	 {863--869},
  year = 	 2012,
  address = 	 {Portugal},
  month = 	 {Oct.},
  abstract = {Abstract: Cooperative localization is one of the fundamental techniques in GPS-denied environments, such as underwater, indoor, or on other planets, where teams of robots use each other to improve their pose estimation. In this paper, we present a novel schema for performing cooperative localization using bearing only measurements. These measurements correspond to the angles of pairs of landmarks located on each robot, extracted from camera images. Thus, the only exteroceptive measurements used are the camera images taken by each robot, under the condition that both cameras are mutually visible. An analytical solution is derived, together with an analysis of uncertainty as a function to the relative pose of the robots. A theoretical comparison with a standard stereo camera pose reconstruction is also provided. Finally, the feasibility and performance of the proposed method were validated, through simulations and experiments with a mobile robot setup. },
category = {Conference Papers},
  label ={C53},
  pdf = "RekleitisIROS2012b.pdf"
}
@InProceedings{ShkurtiIROS2012,
  author = 	 {F. Shkurti and A. Xu and M. Meghjani and J. C. Gamboa Higuera and y. Girdhar and P. Giguere and B. B. Dey and J. Li and A. Kalmbach and C. Prahacs and K. Turgeon and I. Rekleitis and G. Dudek},
  title = 	 {Multi-Domain Monitoring of Marine Environments using a Heterogeneous Robot Team},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages = 	 {1447--1753},
  year = 	 2012,
  address = 	 {Portugal},
  month = 	 {Oct.},
  abstract = {Abstract: In this paper we describe a heterogeneous multirobot system for assisting scientists in environmental monitoring tasks, such as the inspection of marine ecosystems. This team of robots is comprised of a fixed-wing aerial vehicle, an autonomous airboat, and an agile legged underwater robot. These robots interact with off-site scientists and operate in a hierarchical structure to autonomously collect visual footage of interesting underwater regions, from multiple scales and mediums. We discuss organizational and scheduling complexities associated with multi-robot experiments in a field robotics setting. We also present results from our field trials, where we demonstrated the use of this heterogeneous robot team to achieve multi-domain monitoring of coral reefs, based on realtime interaction with a remotely-located marine biologist. },
category = {Conference Papers},
  label ={C52},
  pdf = "RekleitisIROS2012a.pdf",
  vid = "0567_VI.mp4"
}


@InProceedings{RekleitisCRV2012,
  author = 	 {Ioannis Rekleitis},
  title = 	 {Single Robot Exploration: Simultaneous Localization and Uncertainty Reduction on Maps (SLURM)},
  booktitle = {Canadian Conference on Computer and Robot Vision (CRV)},
  pages = 	 {214--220},
  year = 	 2012,
  address = 	 {Toronto, ON, Canada},
  month = 	 {May},
  abstract = {Abstract: During exploration of an unknown environment by a single robot, the robot is driven by two conflicting goals: to explore as fast as possible; and to produce the most accurate map. While fast exploration necessitates  minimizing traversal of already mapped territory, accurate mapping requires that the robot passes over previously explored areas to reduce the localization and map uncertainty. This problem has been labeled as exploration versus exploitation. In this paper the problem of mapping a camera sensor network by a mobile robot has been used to demonstrate the effect that different exploration strategies have on uncertainty and speed of exploration. Simulation results using a realistic noise model are presented for different environments and for different strategies. },
 category = {Conference Papers},
 label ={C51},
  pdf = "RekleitisCRV2012.pdf"
}

@InProceedings{ShkurtiIROS2011,
  author = 	 {Florian Shkurti and Ioannis Rekleitis and Milena Scaccia and Gregory Dudek},
  title = 	 {State Estimation of an Underwater Robot Using Visual and Inertial Information},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages = 	 {5054-5060},
  month = "Sep.",
  year = 	 2011,
  address = 	 {San Francisco, CA, US},
  abstract = {Abstract:This paper presents an adaptation of a vision and inertial-based state estimation algorithm for use in an underwater robot. The proposed approach combines information from an Inertial Measurement Unit (IMU) in the form of linear accelerations and angular velocities, depth data from a pressure sensor, and feature tracking from a monocular downward facing camera to estimate the 6DOF pose of the vehicle. To validate the approach, we present extensive experimental results from field trials conducted in underwater environments with varying lighting and visibility conditions, and we demonstrate successful application of the technique underwater. },
category = {Conference Papers},
  label ={C50},
  pdf = "IROS_2011a.pdf",
  vid = "2051_VI.mp4"
}

@InProceedings{GirdharIROS2011,
	author = {Yogesh Girdhar and Anqi Xu and Bir Bikram Dey and Malika Meghjani and Florian Shkurti and Ioannis Rekleitis and Gregory Dudek},
	title = {{MARE: Marine Autonomous Robotic Explorer}},
	booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	pages = "5048--5053",
	year = "2011",
	month = "Sep.",
	address = "San Francisco, CA, USA",
        abstract = {Abstract: We present MARE, an autonomous airboat robot that is suitable for exploration-oriented tasks, such as inspection of coral reefs and shallow seabeds. The combination of this platform's particular mechanical properties and its powerful software framework enables it to function in a multitude of potential capacities, including autonomous surveillance, mapping, and search operations. In this paper we describe two different exploration strategies and their implementation using the MARE platform. First, we discuss the application of an efficient coverage algorithm, for the purpose of achieving systematic exploration of a known and bounded environment. Second, we present an exploration strategy driven by surprise, which steers the robot on a path that might lead to potentially surprising observations.},
 category = {Conference Papers},
       label ={C49},
        pdf = "IROS_2011b.pdf",
	vid = "1658_VI.mp4"
}

@InProceedings{XuICRA2011,
	author = {Anqi Xu and Chatavut Viriyasuthee and Ioannis Rekleitis},
	title = {Optimal Complete Terrain Coverage using an Unmanned Aerial Vehicle},
	booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
	year = {2011},
	month = {May},
	address = {Shanghai, China},
	pages = {2513--2519},
        abstract = {Abstract: We present the adaptation of an optimal terrain coverage algorithm for the aerial robotics domain. The general strategy involves computing a trajectory through a known environment with obstacles that ensures complete coverage of the terrain while minimizing path repetition. We introduce
a system that applies and extends this generic algorithm to achieve automated terrain coverage using an aerial vehicle. Extensive experimental results in simulation validate the presented system, along with data from over 100 kilometers of successful coverage flights using a fixed-wing aircraft.},
  category = {Conference Papers},
  label ={C48},
  pdf = "ICRA_2011.pdf",
  vid = "0376_VI.mp4"
}


@InProceedings{ShkurtiCRV2011,
  author = 	 {Florian Shkurti and Ioannis Rekleitis  and Gregory Dudek},
  title = 	 {Feature Tracking Evaluation for Pose Estimation in Underwater Environments},
  booktitle = {Canadian Conference on Computer and Robot Vision (CRV)},
  pages = 	 {160-167},
  year = 	 2011,
  address = 	 {St. John, NF Canada},
  abstract = {Abstract: In this paper we present the computer vision component of a 6DOF pose estimation algorithm to be used by an underwater robot. Our goal is to evaluate which feature trackers enable us to accurately estimate the 3D positions of features, as quickly as possible. To this end, we perform an evaluation of available detectors, descriptors, and matching schemes, over different underwater datasets. We are interested in identifying combinations in this search space that are suitable for use in structure from motion algorithms, and more generally, vision-aided localization algorithms that use a monocular camera. Our evaluation includes frame-by-frame statistics of desired attributes, as well as measures of robustness expressed as the length of tracked features. We compare the fit of each combination based on the following attributes: number of extracted keypoints per frame, length of feature tracks, average tracking time per frame, number of false positive matches between frames. Several datasets were used, collected in different underwater locations and under different lighting and visibility conditions },
category = {Conference Papers},
  label ={C47},
  pdf = "CRV_2011.pdf"
}

@InProceedings{RekleitisCIM2010,
  author = 	 {Ioannis  Rekleitis and Robert Sim and Gregory Dudek},
  title = 	 {Cooperative Exploration, Localization, and Visual Map Construction},
  booktitle = {In Brain, Body and Machine, Proceedings of an International Symposium on the Occasion of the 25th Anniversary of the McGill University Centre for Intelligent Machines},
  year = 	 2010,
  editor = 	 {J. Angeles and B. Boulet and J. Clark and J. Kovacses and K. Siddiqi},
  volume = 	 83,
  pages = 	 {227–245},
  address= {Montreal, QC, Canada},
  publisher = {Springer},
  abstract = {Abstract: We examine the problem of learning a visual map of the environment based on discrete landmarks. While making this map we seek to maintain an accurate pose estimate for the mapping robots. Our approach is based on using a team of at least two (heterogeneous) mobile robots in a simple collaborative scheme. In many mapping contexts, a robot moves about the environment collecting data (images, in particular) which are later used to assemble a map; we view the map construction as both a knowledge acquisition and a training process. Without reference to the environment, as a robot collects training images, its position estimate accumulates errors, thus corrupting its estimate of the positions from which observations are taken. We address this problem by deploying a second robot to observe the first one as it explores, thereby establishing a virtual tether, and enabling an accurate estimate of the robot’s position while it constructs the map. We refer to this process as cooperative localization. The images collected during this process are assembled into a representation that allows vision-based position estimation from a single image at a later time. In addition to developing a formalism and concept, we validate our approach experimentally and present quantitative results demonstrating the performance of the method in over 90 trials.},
  category = {Conference Papers},
  label ={C46},
  pdf = "RekleitisCIM2010.pdf"
}

@InProceedings{Rekleitis2010c,
  author =	 {Jean-Luc Bedwani and Ioannis Rekleitis and Francois
                  Michaud and Erick Dupuis},
  title =	 {Multi-Layer Atlas System for Map Management },
  booktitle =	 {Canadian Conference on Computer and Robot Vision (CRV)},
  pages =	 {207-214},
  year =	 2010,
  address =	 {Ottawa, ON, Canada},
  month =	 {May},
  publisher =	 {IEEE},
  abstract = {Abstract:Next generation planetary rovers will require greater autonomous navigation capabilities. Such requirements imply the management of potentially large and rich georeferenced data sets stored in the form of maps. This paper presents the design of a data management system that can be used in the implementation of autonomous navigation schemes for planetary rovers. It also outlines an approach that dynamically manages a variety of data content and the uncertainty of the spatial relationship between two maps; in addition the proposed framework provides basic path planning operations through maps, and the correlation of maps in localization operations. Timing results from a rich data set demonstrate the efficiency of the proposed framework. In addition, experimental results on the usage of our Atlas management system by a rover performing autonomous navigation operations are also presented. },
 category = {Conference Papers},
 label ={C45},
  pdf = "CRV_2010a.pdf"
}

@InProceedings{Rekleitis2010b,
  author =	 {Ioannis Rekleitis and Gregory Dudek and Yasmina
                  Schoueri and Philippe Giguere and Junaed Sattar},
  title =	 {Telepresence across the Ocean},
  booktitle =	 {Canadian Conference on Computer and Robot Vision (CRV)},
  pages =	 {261-268},
  year =	 2010,
  address =	 {Ottawa, ON, Canada},
  month =	 {May},
  publisher =	 {IEEE},
  abstract = {Abstract: We describe the development and deployment of a system for long-distance remote observation of robotic operations. The system we have developed is targeted to exploration, multi-participant interaction, and tele-learning. In particular, we used this system with a robot deployed in an underwater environment in order to produce interactive webcasts of scientific material. The system used a combination of robotic and networking technologies and was deployed and evaluated in a context where students in a classroom were able to observe and participate to a limited degree in the operation of a distant robot being used for environmental assessment. },
category = {Conference Papers},
  label ={C44},
  pdf = "CRV_2010b.pdf"
}


@InProceedings{Rekleitis2010a,
  author =	 {Raphael Mannadiar and Ioannis Rekleitis},
  title =	 {Optimal Coverage of a Known Arbitrary Environment},
  booktitle =	 {IEEE International Conference on Robotics and Automation (ICRA)},
  pages =	 {5525-5530},
  year =	 2010,
  address =	 {Anchorage, AK, USA},
  month =	 {May},
  abstract = {Abstract: The problem of coverage of known space by a mobile robot has many applications. Of particular interest is providing a solution that guarantees the complete coverage of the free space by traversing an optimal path, in terms of the distance travelled. In this paper we introduce a new algorithm based on the Boustrophedon cellular decomposition. The presented algorithm encodes the areas (cells) to be covered as edges of the Reeb graph. The optimal solution to the Chinese Postman Problem (CPP) is used to calculate an Euler tour, which guarantees complete coverage of the available free space while minimizing the path of the robot. In addition, we extend the classical solution of the CPP to account for the entry point of the robot for cell coverage by changing the weights of the Reeb graph edges. Proof of correctness is provided together with experimental results in different environments.},
 category = {Conference Papers},
 label ={C43},
  pdf = "ICRA2010.pdf"
}

@InProceedings{RekleitisCRV2009,
  author = 	 {Yasmina Schoueri and Milena Scaccia and Ioannis Rekleitis},
  title = 	 {Optical Flow from Motion Blurred Color Images},
  booktitle = {Canadian Conference on Computer and Robot Vision (CRV)},
  pages = 	 {1-7},
  year = 	 2009,
  address = 	 {Kelowna, BC, Canada},
  month = 	 {May},
  abstract = {Abstract: This paper presents an algorithm for the estimation of optical flow from a single, motion-blurred, color image. The proposed algorithm is based on earlier work that estimated the optical flow using the information from a single grey scale image. By treating the three color channels separately we improved the robustness of our approach. Since first introduced, different groups have used similar techniques of the original algorithm to estimate motion in a variety of applications. Experimental results from natural as well as artificially motion-blurred images are presented.},
category = {Conference Papers},
  label ={C42},
  pdf = "CRV_2009a.pdf"
}

@InProceedings{RekleitisICRA2009a,
  author = 	 {Ioannis Rekleitis and Jean-Luc Bedwani and Erick Dupuis},
  title = 	 {Autonomous Planetary Exploration using LIDAR data},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  pages = 	 {3025-3030},
  year = 	 2009,
  address = 	 {Kobe, Japan},
  month = 	 {May},
  abstract = {Abstract:  In this paper we present the approach for autonomous planetary exploration developed at the Canadian Space Agency. The goal of this work is to autonomously navigate to remote locations, well beyond the sensing horizon of the rover, with minimal interaction with a human operator. We employ LIDAR range sensors due to their accuracy, long range and robustness in the harsh lighting conditions of space. Irregular Triangular Meshes (ITMs) are used for representing the environment providing an accurate yet compact spatial representation. In this paper a novel path-planning technique through the ITM is introduced, which guides the rover through flatter terrain and safely away from obstacles. Experiments performed in CSAÃ¢s Mars emulation terrain that validate our approach are also presented. },
 category = {Conference Papers},
 label ={C41},
  pdf = "ICRA_2009a.pdf"
}

@InProceedings{RekleitisICRA2009b,
  author = 	 {David Paul Meger and Dimitri Marinakis and Ioannis Rekleitis and Gregory Dudek},
  title = 	 {Inferring a Probability Distribution Function for the Pose of a Sensor Network using a Mobile Robot},
  booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
  pages = 	 {756-762},
  year = 	 2009,
  address = 	 {Kobe, Japan},
  month = 	 {May},
  abstract = {Abstract: In this paper we present an approach for localizing a sensor network augmented with a mobile robot which is capable of providing inter-sensor pose estimates through its odometry measurements. We present a stochastic algorithm that samples efficiently from the probability distribution for the pose of the sensor network by employing Rao-Blackwellization and a proposal scheme which exploits the sequential nature of odometry measurements. Our algorithm automatically tunes itself to the problem instance and includes a principled stopping mechanism based on convergence analysis. We demonstrate the favourable performance of our approach compared to that of established methods via simulations and experiments on hardware.},
 category = {Conference Papers},
 label ={C40},
  pdf = "ICRA_2009b.pdf"
}


@InProceedings{RekleitisASTRA2008,
  author = 	 {Erick Dupuis and Ioannis Rekleitis and Jean-Luc Bedwani and David Gingras and Pierre Allard and Tom Lamarche and Wen-Hong Zhu},
  title = 	 {Autonomous Over-The-Horizon Rover Navigation},
  booktitle = {10th ESA Workshop on Advanced Space Technologies for Robotics and Automation, (ASTRA2008)},
  year = 	 2008,
  month = 	 {Nov.},
  address = 	 {ESTEC, Noordwijk, The Netherlands},
  abstract = {Abstract: This paper presents results from the 2006 and 2007 test campaigns of the Canadian Space Agency's autonomous rover navigation research. In particular, results are provided in the area of terrain modelling, path planning and 3D odometry. Results are also provided for integrated system tests whereby the rover travelled autonomously and semi-autonomously beyond its sensing horizon. It provides a summary of the experimental results that were obtained through two seasons of test campaigns. },
 category = {Conference Papers},
 label ={C39},
  pdf = "ASTRA_2008.pdf"
}

@InProceedings{RekleitisIROS2009a,
  author = 	 {David Meger and   Ioannis Rekleitis and Gregory
  Dudek},
  title = 	 {Heuristic Search Planning to Reduce Exploration Uncertainty},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages = 	 {3382 - 3399},
  year = 	 2008,
  address = 	 {Nice, France,},
  abstract = {Abstract:The path followed by a mobile robot while mapping an environment  (i.e.an exploration trajectory) plays a large role in determining the efficiency of the mapping process and the accuracy  of any resulting metric map of  the  environment. This paper examines some important aspects of path planning in this context: the trade-offs between the speed of the exploration process versus the accuracy of resulting maps; and alternating between exploration of new territory and planning through known maps.The resulting motion planning strategy and associated heuristic are targeted to a robot building a map of an environment assisted  by  a Sensor Network composed of uncalibrated monocular cameras. Anadaptive heuristic exploration strategy basedon A search over a combinedd istance and  uncertainty cost function allows for adaptation to the environment and improvement in mapping accuracy. We assess the technique using an illustrative experiment in areal environment and aset of simulations inaparametric family of idealized environments. },
 category = {Conference Papers},
 label ={C38},
  pdf = "IROS_2008a.pdf"
}

@InProceedings{RekleitisIROS2009b,
  author = 	 {Junaed Sattar and Gregory Dudek and Olivia Chiu and  Ioannis
    Rekleitis and Philippe  Giguere and Alec Mills and Nicolas Plamondon and Chris Prahacs and Yogesh Girdhar and Meyer Nahon and John-Paul Lobos},
  title = 	 {Enabling Autonomous Capabilities in Underwater Robotics},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages = 	 {3628 - 3634},
  year = 	 2008,
  address = 	 {Nice, France},
  abstract = {Abstract: Underwater operations present unique challenges and opportunities for robotic applications. These can be attributed in part to limited sensing capabilities, and to lo- comotion behaviours requiring control schemes adapted to specific tasks or changes in the environment. From enhancing teleoperation procedures, to providing high-level instruction, all the way to fully autonomous operations, enabling autonomous capabilities is fundamental for the successful deployment of underwater robots. This paper presents an overview of the approaches used during underwater sea trials in the coral reefs of Barbados, for two amphibious mobile robots and a set of underwater sensor nodes. We present control mechanisms used for maintaining a preset trajectory during enhanced teleoperations and discuss their experimental results. This is followed by a discussion on amphibious data gathering experi- ments conducted on the beach. We then present a tetherless underwater communication approach based on pure vision for high-level control of an underwater vehicle. Finally the construction details together with preliminary results from a set of distributed underwater sensor nodes are outlined.},
category = {Conference Papers},
  label ={C37},
  pdf = "IROS_2008b.pdf"
}




@InProceedings{RekleitisBMVC2008,
  author = 	 {S. Skaff and J.J. Clark and Ioannis Rekleitis},
  title = 	 {Estimating Surface Reflectance Spectra for Underwater Color Vision},
  booktitle = {British Machine Vision Conference (BMVC)},
  year = 	 2008,
  month = 	 {Sep.},
  pages ={1015-1024},
  address = 	 {Leeds, U.K.},
abstract = {Abstract: This paper introduces a novel mathematical approach to surface spectral reflectance estimation in unknown underwater environments using uncalibrated color cameras. The approach derives surface spectral estimates without explicitly modeling the underwater medium characteristics such as light scattering and absorption. The latter two phenomena are dependent upon two parameters, which are the distance of the object from the camera and the depth of the object in water. The proposed approach does not require these parameters to be specified in advance. Spectral models are useful for underwater applications, where subtle differences in color need to be distinguished. Such models are also useful for fusing information from multiple images. We show that the proposed approach yields promising results.},
category = {Conference Papers},
  label ={C36},
  pdf = "BMVC2008.pdf"

}

@InProceedings{RekleitisISER2008,
  author = 	 {Ioannis Rekleitis and Jean-Luc Bedwani and Erick Dupuis},
  title = 	 {Experimental Results for Over-the-Horizon Planetary Exploration using a LIDAR sensor},
  booktitle = {International Symposium on Experimental Robotics (ISER)},
  pages = 	 {65--77},
  year = 	 2008,
  address = 	 {Athens, Greece},
  month = 	 {Jul.},
  abstract = {Abstract: In this paper we present the experimental results validating the approach for autonomous planetary exploration developed by the Canadian Space Agency (CSA). The goal of this work is to autonomously navigate to remote locations, well beyond the sensing horizon of the rover, with minimal interaction with a human operator. We employ LIDAR range sensors due to their accuracy, long range and robustness in the harsh lighting conditions of space. Irregular triangular meshes (ITM) are used for representing the environment providing an accurate yet compact spatial representation. In this paper after a brief overview of the proposed approach, we discuss the terrain modelling used. A variety of experiments performed in CSA’s Mars emulation terrain that validate our approach are also presented.},
 category = {Conference Papers},
 label ={C35},
  pdf = "marsExplorationISER08.pdf"
}

@InProceedings{Rekleitis2008a,
  author = 	 {Ioannis Rekleitis and Jean-Luc Bedwani and Erick Dupuis and Pierre Allard},
  title = 	 {Path Planning for Planetary Exploration},
  booktitle = {Canadian Conference on Computer and Robot Vision (CRV)},
  pages = 	 {61--68},
  year = 	 2008,
  address = 	 {Windsor, ON, Canada},
  month = 	 {May},
  abstract = {Abstract:  In this paper we present the work done at the Canadian Space Agency on the problem of planetary exploration. One of the main goals is the over-the-horizon navigation of a mobile robot on a Mars like environment. A key component is the ability to plan a path using maps of different resolutions and also to refine/replan when more data becomes available. Our algorithms on path planning and path segmentation are presented together with results from two years of experiments in realistic conditions. },
category = {Conference Papers},
  label ={C34},
  pdf = "CRV2008.pdf"
}

@InProceedings{RekleitisiSAIRAS2008,
  author = 	 {Erick Dupuis and Ioannis Rekleitis and Jean-Luc Bedwani and Tom Lamarche and Pierre Allard Wen-Hong Zhu},
  title = 	 {Over-the-Horizon Autonomous Rover Navigation - Experimental Results},
  booktitle = {International Symposium on Artificial Intelligence, Robotics and Automation in Space (i-SAIRAS)},
  year = 	 2008,
  month = 	 {Feb.},
  address = 	 {Los Angeles, CA, USA},
    abstract = {Abstract: This paper presents the approach for autonomous over-the-horizon rover navigation developed at the Canadian Space Agency. The adopted sensing modality is the one of LIDAR range sensors due to their robustness in the harsh lighting conditions of space. Irregular triangular meshes (ITM) are used for representing the environment providing with an accurate yet compact spatial representation. The ITM is directly usable by path planning algorithms based on efficient graph search such as A*. Experimental results from the 2006 and 2007 extensive field-testing campaigns are provided.},
category = {Conference Papers},
  label ={C33},
  pdf = "iSAIRAS2008.pdf"
}

@InProceedings{Rekleitis-Bedwani-Dupuis-2007,
  author = 	 {Ioannis Rekleitis and Jean-Luc Bedwani and Erick Dupuis},
  title = 	 {Over-the-Horizon, Autonomous Navigation for Planetary Exploration},
  booktitle =	 {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages =	 {2248-2255},
  year =	 2007,
  address =	 {San Diego, CA, USA},
  month =	 {Oct.},
  abstract = {Abstract:  The success of NASA's Mars Exploration Rovers has demonstrated the important benefits that mobility adds to planetary exploration.  Very soon, mission requirements will impose  that planetary exploration rovers drive over-the-horizon in a single command cycle. This will require an evolution of the methods and technologies currently used. This paper presents experimental validation of our over-the-horizon  autonomous planetary navigation. We present our approach to 3D terrain reconstruction from large sparse range data sets, localization and autonomous navigation in a Mars-like terrain. Our approach is based on on-line acquisition of range scans, map construction from these scans, path planning and navigation using the map. An Autonomy Engine supervises the whole process ensuring the safe navigation of the planetary rover. The outdoor experimental results demonstrate the effectiveness of the reconstructed terrain model for rover localization, path planning and motion execution scenario as well as the autonomy capability of our approach. },
 category = {Conference Papers},
 label ={C32},
  pdf = "Rekleitis-Bedwani-Dupuis-2007.pdf"
}

@InProceedings{Rekleitis2007c,
  author = 	 {Dimitrios Marinakis and David Meger and  Ioannis Rekleitis and Gregory Dudek}, 
  title = 	 {Markov Chain Monte-Carlo Inference for Hybrid Sensor Network
  Pose Estimation},
  booktitle =	 {Twenty-Second AAAI Conference on Artificial
  Intelligence (AAAI-07)},
  pages =	 {1089-1094},
  year =	 2007,
  address =	 {Vancouver, BC, Canada},
  month =	 {Jul.},
  abstract = {Abstract: In this paper, we consider a hybrid solution to the sensor net- work position inference problem, which combines a real-time filtering system with information from a more expensive, global inference procedure to improve accuracy and prevent divergence. Many online solutions for this problem make use of simplifying assumptions, such as Gaussian noise models and linear system behaviour and also adopt a filtering strategy which may not use available information optimally. These assumptions allow near real-time inference, while also limit- ing accuracy and introducing the potential for ill-conditioning and divergence. We consider augmenting a particular real- time estimation method, the extended Kalman filter (EKF), with a more complex, but more highly accurate, inference technique based on Markov Chain Monte Carlo (MCMC) methodology. Conventional MCMC techniques applied to this problem can entail significant and time consuming com- putation to achieve convergence. To address this, we propose an intelligent bootstrapping process and the use of parallel, communicative chains of different temperatures, commonly referred to as parallel tempering. The combined approach is shown to provide substantial improvement in a realistic sim- ulated mapping environment and when applied to a complex physical system involving a robotic platform moving in an office environment instrumented with a camera sensor network.},
 category = {Conference Papers},
 label ={C31},
  pdf = "AAAI_2007.pdf"
}

@InProceedings{Rekleitis2007b,
  author = 	 {Ioannis Rekleitis and Jean-Luc Bedwani and  S\'{e}bastien Gemme and Erick Dupuis}, 
  title = 	 {Terrain Modelling for Planetary Exploration},
  booktitle =	 {Canadian Computer and Robot Vision (CRV)},
  pages =	 {243-249},
  year =	 2007,
  address =	 {Montreal, QC, Canada},
  month =	 {May},
  abstract = {Abstract: The success of NASA's Mars Exploration Rovers has demonstrated the important benefits that mobility adds to planetary exploration.  Very soon, mission requirements will impose  that planetary exploration rovers drive autonomously in unknown terrain. This will require an evolution of the methods and technologies currently used. This paper presents  our approach to 3D terrain reconstruction from large sparse range data sets, and the data reduction achieved through decimation. The outdoor experimental results demonstrate the effectiveness of the reconstructed terrain  model for different types of terrain. We also present a first attempt to classify the terrain based on the scans properties. },
 category = {Conference Papers},
 label ={C30},
  pdf = "CRV_2007.pdf"
}
@InProceedings{Rekleitis2006g,
  author = 	 {Erick Dupuis and Joseph Nsasi Bakambu and Ioannis Rekleitis and Jean-Luc Bedwani and Sebastien Gemme and Jean Patrice Rivest-Caissy},
  title = 	 {Autonomous Long-Range Rover Navigation - Experimental Results},
  booktitle =	 {ESA Workshop on Advanced Space Technologies for Robotics and Automation, (ASTRA)},
  pages =	 {125--132},
  year =	 2006,
  address =	 {ESTEC, Noordwijk, The Netherlands},
  month =	 {Nov.},
  abstract = {Abstract: The success of NASA's Mars Exploration Rovers has demonstrated the important benefits that mobility adds to planetary exploration. With ExoMars and the Mars Science Laboratory missions, mobility will play an everincreasing role. Very soon, mission requirements will impose that planetary exploration rovers drive over-thehorizon in a single command cycle. This will require an evolution of the methods and technologies currently used.  The Canadian Space Agency (CSA) has been conducting research in ground control and in autonomous robotics for several years already. One of the target applications is planetary exploration using mobile platforms. The  emphasis of our research program is on reactive on-board autonomy software and long-range rover navigation.   This paper provides experimental results obtained during the summer 2006 test campaign for several of the key technologies developed under our research program. In particular, the paper describes results in the area of terrain modelling, path planning, rover motion control, and rover localisation. Statistical analyses have been performed on test results, where relevant, to provide an indication of success ratios and performance. },
 category = {Conference Papers},
 label ={C29},
  pdf = "ASTRA_2006.pdf"
}

@InProceedings{Rekleitis2006f,
  author = 	 {David Meger and Ioannis Rekleitis and  Gregory Dudek},
  title = 	 {Autonomous Mobile Robot Mapping of a Camera Sensor Network},
  booktitle =	 {The 8th International Symposium on Distributed Autonomous Robotic Systems (DARS) },
  pages =	 {155-164},
  year =	 2006,
  address =	 {Minneapolis, MN, USA},
  month =	 {Jul.},
  abstract = {Abstract: In this paper we examine issues of localization, exploration, and planning in the context of a hybrid robot/camera-network system.  We exploit the ubiquity of camera networks to use them as a source of localization data. Since the Cartesian position of the cameras in most networks is not known accurately, we consider the issue of how to localize such  cameras.  To solve this hybrid localization problem, we subdivide it  into a local problem of camera-parameter estimation combined with a  global planning and navigation problem.  We solve the local camera-calibration problem by using fiducial markers embedded in the robot and by selecting robot trajectories in front of each camera that provide good calibration and field-of-view accuracy.  We propagate information  among the cameras and the successive positions of the robot using an Extended Kalman filter. The paper includes experimental data  from an indoor office environment as well as tests on simulated data sets.},
  category = {Conference Papers},
label ={C28},
  pdf = "DARS_2006.pdf"
}

@InProceedings{Rekleitis2006b,
  author = 	 {Guy Rouleau and Ioannis Rekleitis and R\'{e}gent L'Archev\^{e}que and Eric Martin and Kourosh Parsa and Erick Dupuis},
  title = 	 {Autonomous Capture of a Tumbling Satellite},
  booktitle =	 {IEEE International Conference on Robotics and Automation (ICRA)},
  pages =	 {3855 - 3860},
  year =	 2006,
  address =	 {Orlando, FL, USA},
  month =	 {May},
  abstract = {Abstract: In this paper, we describe a framework for the autonomous capture and servicing of satellites. The work is based on laboratory experiments that illustrate the autonomy and remote-operation aspects. The satellite-capture problem is representative of most on-orbit robotic manipulation tasks where the environment is known and structured, but it is dynamic since the satellite to be captured is in free flight. Bandwidth limitations and communication dropouts dominate the quality of the communication link. The  satellite-servicing scenario is implemented on a robotic test-bed in laboratory settings. },
 category = {Conference Papers},
 label ={C27},
  pdf = "ICRA06_711.pdf"
}

@InProceedings{Rekleitis2006d,
  author = 	 {Chan Sze Kong and Ai Peng New and Ioannis Rekleitis},
  title = 	 {Distributed Coverage with Multi-Robot System},
  booktitle =	 {IEEE International Conference on Robotics and Automation (ICRA)},
  pages =	 { 2423 - 2429},
  year =	 2006,
  address =	 {Orlando, FL, USA},
  month =	 {May},
  abstract = {Abstract: In this paper, we propose an improved algorithm for the multi-robot complete coverage problem.  Real world applications such as lawn mowing, chemical spill clean-up, and humanitarian de-mining can be automated by the employment of a team of autonomous mobile robots. Our approach builds on a single robot coverage algorithm, Boustrophedon decomposition.  The robots are initially distributed through space and each robot is allocated a virtually bounded area to cover.  The area is decomposed into cells where each cell width is fixed.  The decomposed area is represented using an adjacency graph, which is incrementally constructed and shared among all the robots. Communication between the robots is available without any restrictions.  Experiments on both simulated and physical hardware demonstrated the viability of employing the algorithm to perform distributed coverage of a given unknown area with multiple robots. },
 category = {Conference Papers},
 label ={C26},
  pdf = "01642065.pdf"
}

@InProceedings{Rekleitis2006a,
  author = 	 {Joseph Nsasi Bakambu, Sebastien Gemme, Pierre Allard, Tom Lamarche, Ioannis Rekleitis},
  title = 	 {3D Reconstruction of Environments for Planetary Rover Autonomous Exploration},
  booktitle =	 {44th AIAA Aerospace Sciences Meeting and Exhibit },
  pages =	 {1--8},
  year =	 2006,
  address =	 {Reno, NV, USA},
  month =	 {Jan.},
  organization = {American Institute of Aeronautics and Astronautics},
  abstract = {Abstract: In this paper we consider the problem of constructing a 3D environment model for the tele-operation of a planetary rover. We presented our approach to 3D environment reconstruction from large sparse range data sets. In space robotics applications, an accurate and up-to-date model of the environment is very important for a variety of reasons. In particular, the model can be used for safe tele-operation, path planning and mapping points of interest. We propose an on-line reconstruction of the environment using data provided by an on-board high resolution and accurate 3D range sensor (LIDAR). Our approach is based on on-line acquisition of range scans from different view-points with overlapping regions, merge them together into a single point cloud, and then fit an irregular triangular mesh on the merged data. The experimental results demonstrate the effectiveness of our approach in localization, path planning and execution scenario on the Mars Yard located at the Canadian Space Agency.},
category = {Conference Papers},
  label ={C25},
  pdf = "aiaa06.pdf"
}

@InProceedings{Rekleitis2005e,
  author = 	 {Pierre Allard and Joseph Nsasi Bakambu and Tom Lamarche and Ioannis Rekleitis and Erick Dupuis},
  title = 	 {Towards Autonomous Long Range Navigation},
  booktitle =	 {8th International Symposium on Artificial Intelligence, Robotics and Automation in Space (i-SAIRAS)},
  pages =	 {accepted},
  year =	 2005,
  address =	 {Munich, Germany},
  month =	 {Sep.},
  abstract = {Abstract: The recent success of NASA’s Mars Exploration Rovers has demonstrated the important benefits that mobility adds to landed planetary exploration missions.The Canadian Space Agency (CSA) has been conducting research inground control and in autonomous robotics for several years already. One of the target applications is planetary exploration using mobile platforms. The emphasis of our research program is on reactive on-board autonomy software and long-range rover navigation.This paper describes recent activities of the CSA in this area.  Key results are described in the areas of terrain modelling, path planning and rover guidance. },
 category = {Conference Papers},
 label ={C24},
  pdf = "isairas05.pdf"
}


@InProceedings{Rekleitis2005c,
  author = 	 {Ioannis  Rekletis and Gregory Dudek},
  title = 	 {Automated Calibration of a Camera Sensor Network},
  booktitle =	 {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages =	 {401--406},
  year =	 2005,
  address =	 {Edmonton AB, Canada},
  month =	 {Aug.},
  abstract = {Abstract:  In this paper we present a new approach for the online calibration of a camera sensor network. This is the first step towards fully exploiting the potential for collaboration between mobile robots and static sensors sharing the same network. In particular we propose an approach for extracting the 3D pose of each camera in a common reference frame, with the help of a mobile robot. The camera poses can then be used to further refine the robot pose or to perform other tracking tasks. The analytical formulation of the problem of pose recovery is presented together with experimental results of a six node sensor network in different configurations.},
category = {Conference Papers},
  label ={C23},
  pdf = "iros05-0987.pdf"
}


@InProceedings{Rekleitis2005d,
  author = 	 {Gregory Dudek and Michael Jenkin and Chriss Prahacs and Andrew Hogue and Junaed Sattar and Philippe Giguere and Andrew German and Hongyu Liu and Shane Saunderson and Arlene Ripsman and Saul Simhon and Luz Abril Torres-Mendez and Evangelos Milios and Pifu Zhang and Ioannis Rekleitis},
  title = 	 {A Visually Guided Swimming Robot},
  booktitle =	 {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages =	 {1749--1754},
  year =	 2005,
  address =	 {Edmonton AB, Canada},
  month =	 {Aug.},
  abstract = {Abstract: We describe recent results obtained with AQUA, a mobile robot capable of swimming, walking and amphibious operation. Designed to rely primarily on visual sensors, the AQUA robot uses vision to navigate underwater using servobased guidance, and also to obtain high-resolution range scans of its local environment. This paper describes some of the pragmatic and logistic obstacles encountered, and provides an overview of some of the basic capabilities of the vehicle and its associated sensors. Moreover, this paper presents the first ever amphibious transition from walking to swimming.},
 category = {Conference Papers},
 label ={C22},
  pdf = "iros05-1053.pdf"
}


@InProceedings{Rekleitis2005b,
  author = 	 {S\'{e}bastien Gemme, Joseph Nsasi Bakambu and Ioannis
  Rekleitis},
  title = 	 {3D Reconstruction of Environments for Planetary Exploration},
  booktitle =	 {Canadian Conference on Computer and Robot Vision (CRV)},
  pages =	 {594--601},
  year =	 2005,
  address =	 {Victoria, BC, Canada},
  month =	 {May},
  publisher =	 {IEEE},
  abstract = {Abstract: In this paper we present our approach to 3D surface reconstruction from large sparse range data sets. In space robotics constructing an accurate model of the environment is very important for a variety of reasons. In particular, the constructed model can be used for: safe tele-operation, path planning, planetary exploration and mapping of points of interest. Our approach is based on acquiring range scans from different view-points with overlapping regions, merge them together into a single data set, and fit a triangular mesh on the merged data points. We demonstrate the effectiveness of our approach in a path planning scenario and also by creating the accessibility map for a portion of the Mars Yard located in the Canadian Space Agency.},
 category = {Conference Papers},
 label ={C21},
  pdf = "CRV05.pdf"
}

@InProceedings{Rekleitis2005a,
  author = 	 {Ioannis  Rekleitis and Ai Peng New and Howie Choset},
  title = 	 {Distributed Coverage of Unknown/Unstructured Environments by
Mobile Sensor Networks},
  booktitle =	 {3rd International NRL Workshop on Multi-Robot Systems},
  pages =	 {pages 145--155},
  year =	 2005,
  editor =	 {Alan C. Schultz and Lynne E. Parker and Frank Schneider},
  address =	 {Washington, DC, USA},
  month =	 {Mar.},
  publisher =	 {Kluwer},
  abstract = {Abstract: In this paper we present an algorithmic solution for the distributed, complete coverage, path planning problem. Real world applications such as lawn mowing, chemical spill clean-up, and humanitarian de-mining can be automated by the employment of a team of autonomous  mobile robots. Our approach builds on a single robot coverage algorithm. A greedy auction algorithm (a market based mechanism) is used for  task reallocation among the robots. The robots are initially distributed through space and each robot is allocated a virtually bounded area to cover. Communication between the robots is available without any restrictions.},
 category = {Conference Papers},
 label ={C20},
  pdf = "113.pdf"
}

@InProceedings{Rekleitis2004a,
 author = 	 {Ioannis Rekleitis and Vincent Lee-Shue and Ai Peng New and Howie Choset},
 title = 	 {Limited Communication, Multi-Robot Team Based Coverage},
 booktitle =	 {IEEE International Conference on Robotics and Automation (ICRA)},
 pages =	 {3462-3468},
 year =	 2004,
 address =	 {New Orleans, LA, USA},
 month =	 {Apr.},
  abstract = {Abstract: This paper presents an algorithm for the complete coverage of free space by a team of mobile robots. Our approach is based on a single robot coverage algorithm, which divides the target two-dimensional space into regions called cells, each of which can be covered with simple back-and-forth motions; the decomposition of free space in a collection of such cells is known as the Boustrophedon decomposition.  Single robot coverage is  achieved by ensuring that the robot visits every cell.  The new multi-robot coverage algorithm uses the same planar cell-based decomposition as the single robot approach, but provides extensions to handle how teams of robots cover a single cell and how teams are allocated among cells.  This method allows planning to occur in a two-dimensional configuration space for a team of $N$ robots. The robots operate under the restriction that communication between two robots is available only when they are within line of sight of each other. },
 category = {Conference Papers},
 label ={C19},
  pdf = "558_ThP-10_5.pdf"
}

@InProceedings{Rekleitis2004b,
 author = 	 {David Silver and Deryck Morales and Ioannis Rekleitis and Brad Lisien and Howie Choset},
 title = 	 {Arc Carving: Obtaining Accurate, Low Latency Maps from Ultrasonic Range Sensors},
 booktitle =	 {IEEE International Conference on Robotics and Automation (ICRA)},
 pages =	 {1554-1561},
 year =	 2004,
 address =	 {New Orleans, LA, USA},
 month =	 {Apr.},
  abstract = {Abstract: In this paper we present a new technique for improving the azimuth resolution of ultrasonic range sensors frequently used with mobile robots. This improvement is achieved without a significant increase in the latency, or processing delay, of the system. Our approach decreases the azimuth uncertainty of a sensor reading by eliminating portions of the reading that are contradicted by subsequent readings. Our idea bears resemblance to space carving as used by the vision community, where a ray of light is used to define the boundaries of an obstacle. A sonar model similar to that commonly utilized by occupancy grids is used. Our method, termed arc carving, can be used to produce maps that are both accurate and with low enough latency for robust mobile robot navigation. Experimental results verify this approach over spaces as large as 5000 square meters.},
 category = {Conference Papers},
 label ={C18},
  pdf = "252_WP-6_3.pdf"
}

@InProceedings{Rekleitis2003d,
  author = 	 {Brad Lisien and Deryck Morales and David Silver and George Kantor and Ioannis Rekleitis and Howie Choset},
  title = 	 {Hierarchical Simultaneous Localization and Mapping},
  booktitle =	 {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages =	 {448--453},
  year =	 2003,
  address =	 {Las Vegas, NV, USA},
  month =	 {Oct.},
  organization = {IEEE/RSJ},
  abstract = {Abstract: This paper presents a novel method of combining topological and feature-based mapping strategies to create a hierarchical approach to simultaneous localization and mapping (SLAM). More than simply running both processes in parallel, we use the topological mapping procedure to organize local feature-based methods. The result is an autonomous exploration and mapping strategy that scales well to large environments and higher dimensions while confronting the issue of obstacle avoidance. We have obtained successful results of our approach in an area spanning 5000 square meters. },
 category = {Conference Papers},
 label ={C17},
  pdf = "iros03-968.pdf"
}

@InProceedings{Rekleitis2003e,
  author = 	 {Stergios I. Roumeliotis and Ioannis  Rekleitis},
  title = 	 {Analysis of Multirobot Localization Uncertainty Propagation},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
pages =	 {1763--1770},
  year =	 2003,
  address =	 {Las Vegas, NV, USA},
  month =	 {Oct.},
  organization = {IEEE/RSJ},
  abstract = {Abstract: This paper deals with the problem of cooperative localization for the case of large groups of mobile robots. A Kalman filter estimator is implemented and tested for this purpose. The focus of this paper is to examine the effect on localization accuracy of the number N of participating robots and the accuracy of the sensors employed. More specifically, we investigate the improvement in localization accuracy per additional robot as the size of the team increases. Furthermore, we provide an analytical expression for the upper bound on the positioning uncertainty increase rate for a team of N robots as a function of N, the odometric and orientation uncertainty for each robot, and the accuracy of a robot tracker measuring relative positions between pairs of robots. The analytical results derived in this paper are validated in simulation for different test cases. },
category = {Conference Papers},
  label ={C16},
  pdf = "RoumeliotisRekleitisIROS03.pdf"
}

@InProceedings{Rekleitis2003b,
  author = 	 {Ioannis  Rekleitis and Stergios I. Roumeliotis},
  title = 	 {Analytical Expressions for Positioning Uncertainty Propagation in Networks of Robots},
  booktitle =	 {IEEE Mediterranean Conference on Control and Automation},
pages =	 {131--136},
 year =	 2003,
  address =	 {Rhodes, Greece},
  month =	 {Jun.},
  abstract = {Abstract: In this paper we present an analysis of the positioning uncertainty increase rate for a group of mobile robots. The simplified version for a group of N robots moving along one dimension is considered.  The one dimension restriction permits us to extract an exact expression for the accumulation of positioning uncertainty in a group of robots equipped with proprioceptive (odometric in this case) and exteroceptive (relative distance  between robots) sensors. The solution obtained provides insight in the structure of the multirobot localization problem. In addition, it serves both as an approximation and a starting point for examining the more realistic case of N robots moving on a plane. Our derivation is based on a Kalman filter estimator that combines all measurements from all robots in the group. Furthermore, we analyze the effect of initial uncertainty, number of robots (N) and sensor noise on the rate of positioning uncertainty increase. The analytical results derived in this paper and the impact of the different parameters are validated in simulation.},
 category = {Conference Papers},
 label ={C15},
  pdf = "medcontrol03.pdf"
}

@InProceedings{Rekleitis2003c,
author = 	 {Ioannis Rekleitis and Gregory Dudek and Evangelos Milios},
title = 	 {Experiments in Free-Space Triangulation Using Cooperative Localization},
booktitle =	 {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
pages =	 {1777--1782},
year =	 2003,
address =	 {Las Vegas, NV, USA},
month =	 {Oct.},
organization = {IEEE/RSJ},
  abstract = {Abstract: This paper presents a first detailed case study of collaborative exploration of a substantial environment.We use a pair of cooperating robots to test multi-robot environment mapping algorithms based on triangulation of free space (see video). The robots observe one another using a robot tracking sensor based on laser range sensing (LIDAR). The environment mapping itself is accomplished using sonar sensing. The results of this mapping are compared to those obtained using scanning laser range sensing and the scan matching algorithm. We show that with appropriate outlier rejection policies, the sonar-based map obtained using collaborative localization can be as good or, in fact, better than that obtained using what is typically considered to be a superior sensing technology.},
 category = {Conference Papers},
 label ={C14},
  pdf = "iros03-453.pdf"
}

@InProceedings{Rekleitis2003a,
author = {Ioannis Rekleitis and Gregory Dudek and Evangelos Milios},
title = {Probabilistic Cooperative Localization and Mapping in Practice},
booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
pages = {1907--1912},
year = 2003,
address = {Taipei, Taiwan},
organization = {IEEE},
month = {Sep.},
  abstract = {Abstract: In this paper we present a probabilistic framework for the reduction in the uncertainty of a moving robot pose during exploration by using a second robot to assist. A Monte Carlo Simulation technique (specifically, a Particle Filter) is employed in order to model and reduce the accumulated odometric error. Furthermore, we study the requirements to obtain an accurate yet timely pose estimate. A team of two robots is employed to explore an indoor environment in this paper, although several aspects of the approach have been extended to larger groups. The concept behind our exploration strategy has been presented previously and is based on having one robot carry a sensor that acts as a .robot tracker. to estimate the position of the other robot. By suitable use of the tracker as an appropriate motion-control mechanism we can sweep areas of free space between the stationary and the moving robot and generate an accurate graph-based description of the environment. This graph is used to guide the exploration process. Complete exploration without any overlaps is guaranteed as a result of the guidance provided by the dual graph of the spatial decomposition (triangulation) of the environment. We present experimental results from indoor experiments in our laboratory and from more complex simulated experiments. },
 category = {Conference Papers},
 label ={C13},
  pdf = "icra03.pdf"
}


@InProceedings{Rekleitis2002c,
author = 	 {Ioannis  Rekleitis and Gregory Dudek and Evangelos Milios},
title = 	 {Multi-Robot Cooperative Localization:
A Study  of Trade-offs Between  Efficiency and Accuracy},
booktitle = 	 {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
pages =	 {2690-2695},
year =	 2002,
address =	 {Lausanne, Switzerland},
month =	 {Oct.},
organization = {IEEE/RSJ},
  abstract = {Abstract: This paper examines the tradeoffs between different classes of sensing strategy and motion control strategy in the context of terrain mapping  multiple robots. We consider a larger group of robots that can mutually estimate one another's position (in 2D or 3D) and uncertainty using a sample-based  (particle filter) model of uncertainty. Our prior work has dealt with a pair of robots that estimate one another's position using visual tracking and coordinated motion. Here we extend these results and consider a richer set of sensing and motion options. In particular, we focus on issues related to confidence estimation for groups of more than two robots. },
category = {Conference Papers},
  label ={C12},
  pdf = "iros02pdf.pdf"
}

@InProceedings{Rekleitis2001b,
author = {Ioannis Rekleitis and Robert Sim and Gregory Dudek and Evangelos
Milios},
title = {Collaborative exploration for the construction of
visual maps},
booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
pages =	 {1269-1274},
year = 2001,
volume =	 3,
number =	 {ISBN 0-7803-6614-X},
address =	 {Maui, HI, USA},
month = {Oct.},
organization = {IEEE/RSJ},
  abstract = {Abstract: We examine the problem of learning a visual map of the environment while maintaining an accurate pose estimate.  Our approach is based on using two robots in a simple collaborative scheme; in practice, one  of these robots can be much less capable than the other. In many mapping contexts, a robot moves about collecting data (images, in particular) which are later used to assemble a map; we can  think of map construction as a training process. Without outside information, as a robot collects training images, its position estimate accumulates errors, thus corrupting its knowledge of the positions from which observations are taken.  We address this problem by deploying a second robot to observe the first one as it explores, thereby establishing a \emph{virtual tether}, and enabling an accurate estimate of the robot's position while it constructs the map. We refer to this process as \emph{cooperative localization}.  The images collected during this process are assembled into a representation that allows vision-based position estimation from a single image at a later date. In addition to developing a formalism and concept, we validate our results experimentally and present quantitative results demonstrating the performance of the method in over 90 trials. },
category = {Conference Papers},
  label ={C11},
  pdf = "iros01.pdf"
}

@InProceedings{Rekleitis2001a,
author = {Ioannis Rekleitis and Robert Sim and Gregory Dudek and Evangelos
Milios},
title = {Collaborative Exploration for Map Construction},
booktitle = {IEEE International Symposium on Computational Intelligence in Robotics and Automation},
pages =	 {296-301},
year = 2001,
number =	 {ISBN 0-7803-7203-4},
address =	 {Banff, AB, Canada},
month = {Jul.},
organization = {IEEE},
  abstract = {Abstract: We consider the problem of map learning while maintaining ground-truth pose estimates. Map learning is important in tasks that require a model of the environment or some of its features. As a robot collects data, uncertainty about its position accumulates and corrupts its knowledge of the positions from which observations are taken. We address this problem by employing <i>cooperative localization</i>; that is, deploying a second robot to observe the other as it explores, thereby establishing a <i>virtual tether</i>, and enabling an accurate estimate of the robot's position while it constructs the map. This paper presents our approach to this problem in the context of learning a set of visual landmarks useful for pose estimation. In addition to developing a formalism and concept, we validate our results experimentally and present quantitative results demonstrating the performance of the method. },
 category = {Conference Papers},
 label ={C10},
  pdf = "cira01.pdf"
}
@InProceedings{Rekleitis2000b,
author = {Ioannis Rekleitis and Gregory Dudek and Evangelos Milios},
title = {Graph-Based Exploration using Multiple Robots},
booktitle = {5th International Symposium on Distributed Autonomous Robotic Systems (DARS)},
pages = {241-250},
year = 2000,
address = {Knoxville, TN, USA},
month = {Oct.},
publisher = {Springer},
  abstract = {Abstract:We present an approach to multi-robot exploration of large environments. Our method is designed to be robust in the face of arbitrarily large odometry errors or objects with poor reflectance characteristics. The algorithm achieves its robustness by using a team of cooperating agents. The critical aspect of our method is the use of a vision system that sweeps areas of free space and generates a graph-based description of the environment. This graph is used to guide the exploration process and can also be used for subsequent tasks such as place recognition or path planning. As a result of the guidance provided by the dual graph of the triangulated environment, our system can guarantee complete exploration without any overlaps.  We present an algorithmic solution, simulation results, as well as a cost analysis and experimental data. In this approach a pair of robots observe one another's behavior, thus greatly reducing odometry errors. We assume the robots can both directly sense nearby obstacles and see one another (if their view is not obstructed). We have implemented both these capabilities with actual robots in our lab. },
category = {Conference Papers},
  label ={C9},
  pdf = "darsU131.pdf"
}

@InProceedings{Rekleitis2000a,
author = {Ioannis  Rekleitis and Gregory Dudek and Evangelos Milios},
title = {Multi-Robot Collaboration for Robust Exploration},
booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
year = 2000,
address = {San Francisco, CA, USA},
month = {Apr.},
pages = {3164-3169},
  abstract = {Abstract: This paper presents a new sensing modality and stratagem for multirobot exploration. The approach is based on using pairs of robots that observe each other's behavior, acting in concert to reduce odometry errors. We assume the robots can both directly sense nearby obstacles and see each other. This allows the robots to obtain a map of higher accuracy than would be possible with robots acting independently bu reducing inaccuracies that occur over time from dead reckoning errors. Furthermore, by exploiting the ability of the robots to see each other, we can detect opaque obstacles in the environment independently of their surface reflectance properties.  Two different algorithms, based on the size of the environment, are introduced, with a complexity analysis, and experimental results in simulation and with real robots. },
category = {Conference Papers},
  label ={C8},
  pdf = "icra00.pdf"
}

@InProceedings{Rekleitis1999a,
author = {Ioannis  Rekleitis and Vida Dujmovi\'c and Gregory Dudek},
title = {Efficient Topological Exploration},
booktitle = {IEEE International Conference on Robotics and Automation (ICRA)},
year = 1999,
address = {Detroit, MI, USA},
month = {May},
pages = {676-681},
  abstract = {Abstract: We consider the robot exploration of a planar graph-like world. The robot's goal is to build a complete map of its environment. The environment is modeled as an arbitrary undirected planar graph which is initially unknown to the robot. The robot cannot distinguish vertices and edges that it has explored from the unexplored ones. The robot is assumed to be able to autonomously  traverse graph edges, recognize when it has reached a vertex, and enumerate edges incident upon the current vertex. The robot cannot measure distances nor does it have a compass, but it is equipped with a single marker that it can leave at a vertex and sense if the marker is present at a newly visited vertex. The total number of edges traversed while constructing a map of a graph is used as a measure of performance. We present an efficient algorithm for learning an unknown, undirected planar graph by a robot equipped with one marker. One of the main results of this paper is to show that our strategy leads to performance that is typical linear in the size of the graph. Experimental results obtained by running a large collection of example worlds are also presented. },
 category = {Conference Papers},
 label ={C7},
  pdf = "icra99.pdf"
}

@InProceedings{Rekleitis1998,
author = {Ioannis  Rekleitis and Gregory Dudek and Evangelos E.
Milios },
title = {On Multiagent Exploration},
booktitle = {Vision Interface},
year = 1998,
address = {Vancouver, BC, Canada},
month = {Jun.},
pages = {455-461},
  abstract = {Abstract: This paper describes a technique for multi-agent exploration of an unknown environment, that improves the quality of the map by reducing the inaccuracies that occur over time from dead reckoning errors. We present an algorithmic solution, simulation results, as well as a cost analysis and experimental data. The approach is based on using a pair of robots that observe one another's behaviour, thus greatly reducing odometry errors. We assume the robots can both directly sense nearby obstacles and see one another. We have implemented both these capabilities with actual robots in our lab.  By exploiting the ability of the robots to see one another, we can detect opaque obstacles in the environment independent of their surface reflectance properties. },
 category = {Conference Papers},
 label ={C6},
  pdf = "VI98.pdf",
}


@InProceedings{Rekleitis97b,
author = {Ioannis Rekleitis and Gregory Dudek and Evangelos Milios},
title = {Multi-Robot Exploration of an Unknown Environment, Efficiently
Reducing the Odometry Error},
booktitle = {International Joint Conference in Artificial
Intelligence (IJCAI)},
volume = 2,
year = 1997,
publisher = {Morgan Kaufmann Publishers, Inc.},
address = {Nagoya, Japan},
month = {Aug.},
pages = {1340-1345},
  abstract = {Abstract: This paper deals with the intelligent exploration of an unknown environment by autonomous robots. In particular, we present an algorithm and associated analysis for collaborative exploration using two mobile robots. Our approach is based on robots with range sensors limited by distance. By appropriate behavioural strategies, we show that odometry (motion) errors that would normally present problems for mapping can be severely reduced. Our analysis includes polynomial complexity bounds and a discussion of possible heuristics. },
 category = {Conference Papers},
 label ={C5},
  pdf = "IJCAI97.pdf"
}

@InProceedings{Rekleitis96b,
author = "Ioannis  Rekleitis",
title = "Optical Flow Recognition from the Power Spectrum of a Single
Blurred Image",
booktitle = "International Conference in Image Processing",
year = 1996,
organization = {IEEE Signal Processing Society},
address = "Lausanne, Switzerland",
month = "Sep.",
  abstract = {Abstract:  In this paper a new technique for calculation of the optical flow is presented.  When there is motion in the observed scene, an image taken will be motion blurred (to a degree depending on the exposure time). Up to now most of the algorithms for estimating the motion in a scene ignored motion blur and treated it as noise. On the contrary, motion blur is structured information and in certain cases can be used to infer the velocities locally. This new approach uses the information of the motion blur in the frequency domain to extract the orientation and the magnitude of the velocity - optical flow.},
 category = {Conference Papers},
 label ={C4},
  pdf = "ICIP96_P987.pdf"
}

@InProceedings{Dudek96b,
author = "Gregory Dudek and Paul Freedman and Ioannis  Rekleitis",
title = "Environment Exploration Using ``Just-in-Time'' Sensor Fusion",
pages = "175-182",
booktitle = "Vision Interface",
year = 1996,
address = "Toronto, ON, Canada",
month = "May",
  abstract = {Abstract: This paper describes an approach to combining range data from both a set of sonar sensors as well as from a directional laser range finder to efficiently take advantage of the characteristics of both types of devices when exploring and mapping unknown worlds. We call our approach ``just in time sensing'' because it uses the more accurate but constrained laser range sensor only as needed, based upon a preliminary interpretation of sonar data. In this respect, it resembles ``just in time'' inventory control which attempts to judiciously obtain materials for industrial manufacturing only when and as needed. Experiments with a mobile robot equipped with sonar and a laser rangefinder demonstrate that by judiciously using the more accurate but more complex laser rangefinder to deal with the well-known ambiguity which arises in sonar data, we are able to obtain a much better map of an interior space at little additional cost (in terms of time and computational expense).},
 category = {Conference Papers},
 label ={C3},
  pdf = "vi96b.pdf"
}

@InProceedings{Rekleitis96,
author = "Ioannis  Rekleitis",
title = "Steerable Filters and Cepstral Analysis for Optical Flow Calculation
from a Single Blurred Image",
pages = "159-166",
booktitle = "Vision Interface",
year = 1996,
address = "Toronto, ON, Canada",
month = "May",
  abstract = {Abstract:  This paper considers the explicit use of motion blur to compute the Optical Flow. In the past, many algorithms have been proposed for estimating the relative velocity from one or more images. The motion blur is generally considered an extra source of noise and is eliminated, or is assumed nonexistent.  Unlike most of these approaches, it is feasible to estimate the Optical Flow map using only the information encoded in the motion blur. An algorithm that estimates the velocity vector of an image patch using the motion blur only is presented; all the required information comes from the frequency domain. The first step consists of using the response of a family of steerable filters applied on the log of the Power Spectrum in order to calculate the orientation of the velocity vector. The second step uses a technique called Cepstral Analysis. More precisely, the log power spectrum is treated as another signal and we examine the Inverse Fourier Transform of it in order to estimate the magnitude of the velocity vector. Experiments have been conducted on artificially blurred images and with real world data.},
 category = {Conference Papers},
 label ={C2},
  pdf = "vi96a.pdf"
}

@InProceedings{Rekleitis_ICRA1996,
author = "Gregory Dudek and Paul Freedman and Ioannis  Rekleitis",
title = "Just-in-time sensing: efficiently combining sonar and laser
range data for exploring unknown worlds",
volume = "1",
pages = "667-671",
booktitle = "IEEE International Conference on Robotics and Automation (ICRA)",
address={Minneapolis, MN, USA},
year = 1996,
month = "Apr.",
abstract = {Abstract: This paper describes an approach to combining range data from both a set of sonar sensors as well as from a directional laser range finder to efficiently take advantage of the characteristics of both types of devices when exploring and mapping unknown worlds. We call our approach ``just in time sensing'' because it uses the more accurate but constrained laser range sensor only as needed, based upon a preliminary interpretation of sonar data. In this respect, it resembles ``just in time'' inventory control which attempts to judiciously obtain materials for industrial manufacturing only when and as needed. Experiments with a mobile robot equipped with sonar and a laser rangefinder demonstrate that by judiciously using the more accurate but more complex laser rangefinder to deal with the well-known ambiguity which arises in sonar data, we are able to obtain a much better map of an interior space at little additional cost (in terms of time and computational expense).},
category = {Conference Papers},
label ={C1},
pdf = "ICRA96.pdf"

}

@PhdThesis{Rekleitis2003,
author = 	 {Ioannis  Rekleitis},
title = 	 {Cooperative Localization and Multi-Robot Exploration},
school = 	 {School of Computer Science, McGill University},
year = 	 2003,
address =	 {Montreal, QC, Canada},
month =	 {Feb.},
pdf="thesis.pdf",
abstract = {Abstract: This thesis has two main contributions. The first contribution is the use  of cooperative localization for  decoupling  the positional error of a moving robot from its environment.  The second contribution is the development of efficient multi-robot exploration strategies for an unknown environment.

The proposed method is designed to be robust in the face of arbitrarily large odometry errors or objects with poor reflectance characteristics. Central to  the exploration strategy is a  sensor (robot tracker) mounted on a robot that could track a second mobile robot and accurately report its relative position. Our exploration strategies use the robot tracker sensor to sweep areas of free space between stationary and moving robots and to generate a graph-based description of the environment. This graph is used to guide the exploration process. Depending on the size of the environment relative to the range of the robot tracker, different spatial decompositions are used: a triangulation or a trapezoidal decomposition of the free space. Complete exploration without any overlaps is guaranteed as a result of the guidance provided by the dual graph of the spatial decomposition of the environment.

The uncertainty in absolute robot positions and the resulting uncertainty in the map is reduced through the use of a probabilistic framework based on particle filtering (a Monte Carlo simulation technique). Particle filtering is a probabilistic sampling technique used to efficiently  model complex probability distributions that cannot be effectively described using classical methods (such as Kalman filters).

We present experimental results from two different implementations of the robot tracker sensor, in simulated and in real environments. The accuracy of the resulting map increases with the use of cooperative localization. Furthermore, the deterioration of the floor conditions did not affect the quality of the map verifying the decoupling of positioning error from the environment.},
category = {Thesis},
label ={O3},
pdf="thesis.pdf"
}

@MastersThesis{Rekleitis95,
author = "Ioannis  Rekleitis",
title = "Visual Motion Estimation based on Motion Blur Interpretation",
school = "School of Computer Science, McGill University",
year = 1995,
month = "Nov.",
address = "Montreal, Quebec, Canada",
abstract = {Abstract: When the relative velocity between the different objects in a scene and the camera is relative large -- compared with the camera's exposure time -- in the resulting image we have a distortion called motion blur. In the past, a lot of algorithms have been proposed for estimating the relative velocity from one or, most of the time, more images. The motion blur is generally considered an extra source of noise and is eliminated, or is assumed nonexistent. Unlike most of these approaches, it is feasible to estimate the Optical Flow map using only the information encoded in the motion blur. This thesis presents an algorithm that estimates the velocity vector of an image patch using the motion blur only, in two steps. The information used for the estimation of the velocity vectors is extracted from the frequency domain, and the most computationally expensive operation is the Fast Fourier Transform that transforms the image from the spatial to the frequency domain. Consequently, the complexity of the algorithm is bound by this operation into O(n log(n)). The first step consists of using the response of a family of steerable filters applied on the log of the Power Spectrum in order to calculate the orientation of the velocity vector. The second step uses a technique called Cepstral Analysis. More precisely, the log power spectrum is treated as another signal and we examine the Inverse Fourier Transform of it in order to estimate the magnitude of the velocity vector. Experiments have been conducted on artificially blurred images and with real world data, and an error analysis on these results is also presented.},
category = {Thesis},
label ={O2},
pdf = "MSc.thesis.pdf"
}

@bscthesis{Rekleitis1991,
author = {Ioannis Rekleitis and Dimitris Mavropoulos and Athanasios
Athanasopoulos},
title = {{An Image Processing Environment for the Tektronix Workstation}},
booktitle = {Bachelor Thesis (In Greek)},
month = {Jun.},
year = {1991},
school = {Department of Informatics, University of Athens},
address = {Athens, Greece},
abstract = {Abstract: The work of this project was to create an image processing environment for a Tektronix workstation},
category = {Thesis},
label ={O1},
pdf = ""
}

@InProceedings{Cottingham2020,
  author = 	 {Kathryn L. Cottingham and Kathleen C. Weathers and Alberto {Quattrini Li} and David A. Lutz and Mary E. Lofton and Jennifer A. Brentrup and Shannon L. LaDeau and Bethel Steele and Holly A. Ewing and Cayelan C. Carey and Annie Bourbonnais and Denise A. Bruesewitz and Michael C. Dietze and Mark J. Ducey and Kenneth M. Johnson and Michael W. Palace and Ioannis Rekleitis and Paolo Stegagno and Devin J. Balkcom and Whitney S. Beck and Ruchi Bhattacharya and Ludmila S. Brightenti and Sarah H. Burnet and Barbara D. Cook and Christina Herrick and Mingi Jeong and Kizito Masaba and Ian M. McCullough and Christopher N. Roman and Monika Roznere and Hannah J. Rubin and V.S. Subramahnian and Franklin Sullivan and Nicole K. Ward and Jacob A Zwart},
  title = 	 {Predicting cyanobacterial blooms in freshwater lakes: the promise of new partners, tools, and technologies},
  booktitle = { ESA Virtual Meeting},
  year = 	 2020,
  month = 	 {Aug.},
  address = 	 {Virtua)},
  abstract = {Abstract: Background/Question/Methods
One of the foremost challenges in science is successfully predicting whether something will happen at a new place or time. Until recently, ecologists have assumed that reliable predictions would be possible only after we attained complete understanding, and so we did not try to predict the phenomena of interest. However, inspired by the push for iterative near-term ecological forecasting led by the Ecological Forecasting Initiative, ecologists are beginning to make predictions even with incomplete understanding – spurred by the idea that we will learn more by forecasting and failing, than by sticking with business as usual.

Near-term, iterative forecasts are urgently needed in fields where the phenomena of interest impact human health and well-being. For example, nuisance cyanobacterial blooms, which threaten the irreplaceable ecosystem services provided by freshwater lakes, are growing in frequency, magnitude, and duration worldwide. While the ultimate causes of blooms are characterized, identifying the proximate triggers of these events and forecasting incipient blooms are still major challenges due, in part, to the limited spatial and temporal resolution of the available data and the lack of real-time or near-real-time data integration.

This poster will describe several ongoing interdisciplinary, interconnected projects to predict cyanobacterial blooms using new tools and technologies.

Results/Conclusions

Work to date suggests that our partnerships, tools, and technologies will lead to scalable models for predicting cyanobacterial blooms. For example, we have identified the dominant sources of uncertainty in near-term predictions for a focal cyanobacterial species using relatively simple Bayesian state-space models fit to an ongoing weekly time series from oligotrophic Lake Sunapee, NH. This work provides the first estimate of uncertainty contributions for cyanobacterial predictions in an oligotrophic lake and suggests that more complex models, or model ensembles, that incorporate both abiotic and biotic factors are needed. This finding informs a new project to generate bloom forecasts from ‘big data’ collected across space and through time using sensors on fixed buoys, autonomous surface vehicles (robots), and unmanned aerial vehicles (drones). We will integrate these data streams in near real-time, then use machine learning and Bayesian modeling to improve bloom prediction capabilities, testing our models with data from traditional field sampling programs and state-of-the-art satellite remote sensing platforms. Our overarching goal is to generate bloom forecasts that will help lake managers preemptively manage water quality, provide advance warning of potential recreational water closures, and inform policy making.},
  label ={N25},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = ""
}


@InProceedings{KarapetyanIROS2019Workshop,
  author = 	 {Nare Karapetyan and Ioannis Rekleitis},
  title = 	 {Coverage of Rivers with an Autonomous Surface Vehicles},
  booktitle = {Informed Scientific Sampling in Large-scale Outdoor Environments Workshop, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2019,
  month = 	 {Nov.},
  address = 	 {Singapore (Virtual)},
  abstract = {Abstract: },
  label ={N24},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = ""
}


@InProceedings{KarapetyanIROS2019Workshop,
  author = 	 {Nare Karapetyan and Ioannis Rekleitis},
  title = 	 {Coverage of Rivers with an Autonomous Surface Vehicles},
  booktitle = {Informed Scientific Sampling in Large-scale Outdoor Environments Workshop, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2019,
  month = 	 {Nov.},
  address = 	 {Macau},
  abstract = {Abstract: Autonomous area coverage is an important problem arising in environmental monitoring, search and rescue,infrastructure monitoring, and survey operations. Particularly when an area of interest has unstructured boundaries, such as rivers, the state-of the art approaches of area coverage path planning are not directly applicable. In addition, during coverage operations, and path planning in general, in dynamic environments inaccurate navigation from waypoint to waypoint presents extra challenges. In this work we present an overview of different patterns that can be utilized for river coverage in surveying, water sampling, and bathymetric mapping operations. In addition we discuss how a reactive method can be used for more accurate navigation when the environmental forces affect the navigation of the surface vehicle. Described methods have been tested utilizing an autonomous surface vehicle on different segments of the Congaree River in South Carolina, USA. All experiments resulted in total of more than 55km of coverage trajectories in the field.},
  label ={N23},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = ""
}


@InProceedings{QuattriniLiIROS2019Workshop,
  author = 	 {Alberto {Quattrini Li} and Holly Ewing and Annie Bourbonnais and Paolo Stegagno and Ioannis Rekleitis and Denise Bruesewitz and Kathryn Cottingham and Devin Balkcom and Mark Ducey and Kenneth Johnson and Stephen Licht and David Lutz and Jason O'Kane and Michael Palace and Christopher Roman and V. S. Subrahmanian and Kathleen Weathers},
  title = 	 {Computational methods and autonomous robotics systems for modeling and predicting harmful cyanobacterial blooms},
  booktitle = {Informed Scientific Sampling in Large-scale Outdoor Environments Workshop, IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  year = 	 2019,
  month = 	 {Nov.},
  address = 	 {Macau},
  abstract = {Abstract: This extended abstract describes a joint effort to model and predict harmful cyanobacterial blooms in lakes of an interdisciplinary team with expertise in big data, environmental science, ecology, human demography, instrumentation, and robotics from four states: Maine, New Hampshire, Rhode Island, and South Carolina. This project uniquely integrates current methodology for data collection, including remote sensing and manual limnological sampling, together with heterogeneous robotic and sensor systems to extend the spatial and temporal sampling. Such big amount of data will be analyzed and processed using ensemble prediction models for determining the development and severity of blooms both in time and space (when and where) and for testing limnological hypotheses. While this project just started and does not have new result yet, this paper provides insights on open research questions and the methodology used, as well as best practices for interdisciplinary collaboration across different departments, institutions, and citizen scientists.},
  label ={N22},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "2019_iros_ippasws_epscor.pdf"
}

@InProceedings{KarapetyanOceans2019,
  author = 	 {Nare Karapetyan and Jason Moulton and Ioannis Rekleitis},
  title = 	 {Dynamic Autonomous Surface Vehicle Control and Applications in Environmental Monitoring},
  booktitle = {MTS/IEEE OCEANS -  Seattle},
  year = 	 2019,
  doi ={https://doi.org/10.23919/OCEANS40490.2019.8962820},
  pages ={1-6},
  month ={Oct.},
  address = 	 {Seattle, WA, USA, (Third place student poster competition)},
  abstract = {Abstract: This paper addresses the problem of robotic operations in the presence of adversarial forces. We presents a complete framework for survey operations: waypoint generation, modelling of forces and tuning the control. In many applications of environmental monitoring, search and exploration, and bathymetric mapping, the vehicle has to traverse in straight lines parallel to each other, ensuring there are no gaps and no redundant coverage. During operations with an Autonomous Surface Vehicle (ASV) however, the presence of wind and/or currents produces external forces acting on the vehicle which quite often divert it from its intended path. Similar issues have been encountered during aerial or underwater operations. By measuring these phenomena, wind and current, and modelling their impact on the vessel, actions can be taken to alleviate their effect and ensure the correct trajectory is followed.
},
  label ={N21},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = ""
}

@inproceedings{RahmanICRA2019Workshop,
  title={Visual-Acoustic SLAM for Underwater Caves},
  author={Rahman, Sharmin and Li, Alberto Quattrini and Rekleitis, Ioannis},
  booktitle={Underwater Robotics Perception Workshop - ICRA 2019},
  year={2019},
  abstract = {Abstract: Underwater caves are extremely challenging environment for perception, due to the absence of natural light and the highly unstructured nature of such environment, making it also dangerous and cognitively heavy even for highly skilled divers. This paper presents an overview of our previous works for underwater cave mapping which combines data from multiple sensors to assist the divers by reducing the cognitive loads.  The challenges of the underwater environment augmented by the complete absence of natural light and the effects of sharp shadows are discussed together with the contributions of the different sensing modalities. A tightly-coupled keyframebased SLAM framework with loop-closing and relocalization capabilities combining visual, inertial, depth, and acoustic sensors has been described together with the design of a sensor suite for collecting data in the challenging environment of underwater caves. Experimental results illustrate the accuracy and robustness of the proposed methodology from a cavern at Ballroom, Ginnie Springs, FL, USA. },
  label ={N20},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "RahmanICRA2019Workshop.pdf"
}

@inproceedings{RahmanOceans2018,
  title={A Modular Sensor Suite for Underwater Reconstruction},
  author={Rahman, Sharmin and Karapetyan, Nare and Li, Alberto Quattrini and Rekleitis, Ioannis},
  booktitle={MTS/IEEE OCEANS -  Charleston},
  pages={1--6},
  year={2018},
  organization={IEEE},
  abstract = {Abstract: This paper presents the design, development, and application of a sensor suite, made with the explicit purpose of localizing and mapping in underwater environments. The design objectives of such an underwater sensor rig include simplicity of carrying, ease of operation in different modes, and data collection. The rig is equipped with stereo camera, inertial measurement unit (IMU), mechanical scanning sonar, and depth sensor. The electronics are enclosed in a water-proof PVC tube tested to sixty meters. The contribution of this paper is twofold: first, we open-source the design providing detailed instructions that are made available online; second, we discuss lessons learned as well as some successful applications where the presented sensor suite has been operated by divers.},
  label ={N19},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "RahmanOceans2018.pdf",
}
@inproceedings{ModasshirOceans2018,
  title={MDNet: Multi-Patch Dense Network for Coral Classification},
  author={Md Modasshir and Alberto Quattrini Li and Ioannis Rekleitis},
  booktitle={MTS/IEEE OCEANS -  Charleston},
  pages={1--6},
  year={2018},
  organization={IEEE},
  abstract = {Abstract: Classifying coral species from visual data is a challenging task due to significant intra-species variation, high interspecies similarity, inconsistent underwater image clarity, and high dataset imbalance. In addition, point annotation, the labeling method used for coral reef images by marine biologists, is prone to mislabeling. Point annotation also makes existing datasets incompatible with state-of-the-art classification methods which use the bounding box annotation technique. In this paper, we present a novel end-to-end Convolutional Neural Network (CNN) architecture, Multi-Patch Dense Network (MDNet) that can learn to classify coral species from point annotated visual data. The proposed approach utilizes patches of different scale centered on point annotated objects. Furthermore, MDNet utilizes dense connectivity among layers to reduce over-fitting on imbalanced datasets. Experimental results on the Moorea Labeled Coral (MLC) benchmark dataset are presented. The proposed MDNet achieves higher accuracy and average class precision than the state-of-the-art approaches. },
  label ={N18},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "ModasshirOceans2018.pdf",
}
@inproceedings{MoultonOceans2018,
  title={An Autonomous Surface Vehicle for Long Term Operations},
  author={Jason Moulton and Nare Karapetyan  and Sharon Bukhsbaum and Chris McKinney and  Sharaf Malebary and George Sophocleous and Alberto {Quattrini Li} and Ioannis Rekleitis},
  booktitle={MTS/IEEE OCEANS -  Charleston},
  pages={1--6},
  year={2018},
  organization={IEEE},
  abstract = {Abstract: Environmental monitoring of marine environments presents several challenges: the harshness of the environment, the often remote location, and most importantly, the vast area it covers. Manual operations are time consuming, often dangerous, and labor intensive. Operations from oceanographic vessels are costly and limited to open seas and generally deeper bodies of water. In addition, with lake, river, and ocean shoreline being a finite resource, waterfront property presents an ever increasing valued commodity, requiring exploration and continued monitoring of remote waterways. In order to efficiently explore and monitor currently known marine environments as well as reach and explore remote areas of interest, we present a design of an autonomous surface vehicle (ASV) with the power to cover large areas, the payload capacity to carry sufficient power and sensor equipment, and enough fuel to remain on task for extended periods. An analysis of the design and a discussion on lessons learned during deployments is presented in this paper.},
  label ={N17},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "MoultonOceans2018.pdf",
}
@inproceedings{HansenOceans2018,
  title={Autonomous Marine Sampling Enhanced by Strategically Deployed Drifters in Marine Flow Fields},
  author={Johanna Hansen and Sandeep Manjanna and Alberto Quattrini Li and Ioannis Rekleitis and Gregory Dudek},
  booktitle={MTS/IEEE OCEANS -  Charleston},
  pages={1--6},
  year={2018},
  organization={IEEE},
  abstract = {Abstract: We present a transportable system for ocean observations in which a small autonomous surface vehicle (ASV) adaptively collects spatially diverse samples with aid from a team of inexpensive, passive floating sensors known as drifters. Drifters can provide an increase in spatial coverage at little cost as they are propelled about the survey area by the ambient flow field instead of with actuators. Our iterative planning approach demonstrates how we can use the ASV to strategically deploy drifters into points of the flow field for high expected information gain, while also adaptively sampling the space. In this paper, we examine the performance of this heterogeneous sensing system in simulated flow field experiments.},
  label ={N16},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "HansenOceans2018.pdf",
}
@inproceedings{MalebaryOceans2018,
  title={Experimental Analysis of Radio Communication Capabilities of Multiple Autonomous Surface Vehicles},
  author={Sharaf Malebary and Jason Moulton and Alberto Quattrini Li and Ioannis Rekleitis},
  booktitle={MTS/IEEE OCEANS -  Charleston},
  pages={1--6},
  year={2018},
  organization={IEEE},
  abstract = {Abstract: Autonomous exploration and rescue vehicles have been gaining wide interest over the past few years. Nowadays, demonstrations showed that those vehicles can fly, dive, surf, or drive while carrying out missions autonomously in some specific scenarios. Monitoring vehicles during missions is a crucial and challenging task to avoid the unnecessary cost of losing vehicles or potential accidents. In this paper, we present a cheap yet effective way for monitoring and communicating with autonomous vehicles over long distances by using off-the-shelf 900 MHz modems namely RFD 900+ and high gain antennas. Although the 900 MHz band has been around for over two decades, no complete analysis exists providing guidelines to use off the shelf modems for point-to-point and multi-point communications. Our main contribution is to provide experimental analysis of the communication capabilities in point-to-point and multi-point scenarios in both line of sight (LOS) and non line of sight (NLOS) using an affordable setup (\$70 per modem). Experiments were carried out using autonomous surface vehicles (ASVs) as remote nodes and computers as Ground Control Stations (GCSs).},
  label ={N15},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "MalebaryOceans2018.pdf",
}


@InProceedings{Rekleitis2017MRSAbstract,
  author       = {Sandeep Manjanna and Alberto Quattrini Li and Ryan N. Smith and Ioannis Rekleitis and Gregory Dudek},
  title        = {Adaptive Exploration and Sampling by Heterogeneous Robotic Team},
  booktitle    = {International Symposium on Multi-Robot and Multi-Agent Systems},
  month        = {Dec.},
  address      = {Los Angeles, CA, USA},
  year	       = {2017},
  abstract = {Abstract: .},
  label ={N14},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  pdf = "MRS17_POSTER_10.pdf",
  vid = "MRS2017abs.mp4"
}

@inproceedings{rahman2017iros,
  Author = {Sharmin Rahman and Alberto {Quattrini Li} and Ioannis Rekleitis},
  Booktitle = {IROS2017 Abstract},
  Title = {Underwater Cave Mapping: Stereo Visual SLAM with IMU and Sonar},
  Year = {2017},
  abstract = 	 {Abstract:},
 address = {Vancouver, BC, Canada},
 category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  label ={N13}, 
  pdf = "IROS2017AbsCave.pdf"
}

@inproceedings{quattrini2017iros,
  Author = {Alberto {Quattrini Li} and Phani Krishna Penumarthi  and Jacopo Banfi and Nicola Basilico and Francesco Amigoni and Ioannis Rekleitis and Jason O'Kane and Srihari Nelakuditi},
  Booktitle = {IROS2017 Abstract},
  Title = {Online Construction of Communication Maps for Robust Multirobot Deployments},
  Year = {2017},
  abstract = 	 {Abstract:},
 address = {Vancouver, BC, Canada},
 category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  label ={N12}, 
  pdf = "IROS2017AbsComs.pdf"
}

@inproceedings{quattrini2017rssrcw,
  Author = {Alberto {Quattrini Li} and Phani Krishna Penumarthi  and Jacopo Banfi and Nicola Basilico and Francesco Amigoni and Ioannis Rekleitis and Jason O'Kane and Srihari Nelakuditi},
  Booktitle = {RSS2017 (Robotics Science and Systems) Workshop on ``Robot Communication in the Wild''},
  Title = {On Building Communication Maps for Reliable Multirobot Deployments},
  Year = {2017},
 address = {Boston, MA, USA},
 abstract = 	 {Abstract:},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  label ={N11}, 
  pdf = "RSS2017ComWork.pdf"
}

@InProceedings{DohertyCAM16X,
  author = 	 {Sean Doherty and Wout De Backer and Arturs P. Bergs and Ramy Harik and Michel van Tooren and Ioannis Rekleitis},
  title = 	 {Selective Directional Reinforcement of Structures for Multi-Axis Additive Manufacturing},
  booktitle = {CAMX, The composites and advanced materials expo},
  year = 	 2016,
  month = 	 {Sep.},
  address = 	 {Anaheim, CA, USA},
  abstract = 	 {Abstract: Additive manufacturing has become a well-recognized method of manufacturing and has steadily become more accessible as it allows the designer to prototype ideas, products and structures unconceivable with subtractive manufacturing techniques for both consumer grade and industrial grade applications. In general, additively manufactured parts have reduced mechanical properties in the build direction of the print. Moreover, for shell-like structures, buckling is a dominant failure mode when loaded in compression, which introduces additional bending stresses in the interface between two subsequently printed layers. There is a need for reinforcement of both the material and the structures. A promising solution to the above mentioned problems is addition of local reinforcements constructed in the build direction of the base geometry. In this paper, a solution for these process defects and structural instabilities is proposed through modification of toolpathing and addition of both global and local features with multi-orientation slicing techniques. Designed for use with the broad range of capabilities of modern industrial robotics, a 6-axis directional reinforcement can be added to various types of base geometries. Through examples, two fundamental cases are elaborated: an example of the multi-axis deposition is discussed in this paper by adding a predefined feature to the side of existing geometry and in a second case, a set of global stiffeners is added to a base geometry. The methods discussed in this paper show great promise for additive manufacturing on 6 degree of freedom platforms.},
   category = {Editorials; Lightly Refereed Conference and Workshop Papers},
 label ={N10}, 
  pdf = "DohertyCAM16X.pdf"
}

@InProceedings{QuattriniLiOceans2016,
  author = 	 {A. {Quattrini Li} and A. Coskun and S. M. Doherty and S. Ghasemlou and A. S. Jagtap and M. Modasshir and S. Rahman and A. Singh and M. Xanthidis and J. M. O’Kane and I. Rekleitis},
  title = 	 {Vision-Based Shipwreck Mapping: on Evaluating Features Quality and Open Source State Estimation Packages
},
  booktitle = {MTS/IEEE OCEANS - Monterrey},
  year = 	 2016,
  pages = 	 {1-10},
  month = 	 {Sep.},
  abstract = 	 {Abstract: Historical shipwrecks are important for many rea- sons, including historical, touristic, and environmental. Cur- rently, limited efforts for constructing accurate models are performed by divers that need to take measurements manually using a grid and measuring tape, or using handheld sensors. A commercial product, Google Street View1, contains underwater panoramas from select location around the planet including a few shipwrecks, such as the SS Antilla in Aruba and the Yongala at the Great Barrier Reef. However, these panoramas contain no geometric information and thus there are no 3D representations available of these wrecks.
This paper provides, first, an evaluation of visual features quality in datasets that span from indoor to underwater ones. Second, by testing some open-source vision-based state estimation packages on different shipwreck datasets, insights on open chal- lenges for shipwrecks mapping are shown. Some good practices for replicable results are also discussed.},
   category = {Editorials; Lightly Refereed Conference and Workshop Papers},
 label ={N9}, 
  pdf = "RekleitisOceansMonterrey2016.pdf"
}



@InProceedings{RekleitisICRAWork2016,
  author = 	 {A. Quattrini Li and A. Coskun and S. M. Doherty and S. Ghasemlou and A. S. Jagtap and M. Modasshir and S. Rahman and A. Singh and M. Xanthidis and J. M. O’Kane and I. Rekleitis},
  title = 	 {On Understanding the Challenges in Vision-Based Shipwreck Mapping},
  booktitle = {ICRA 2016 Workshop on Marine Robot Localization and Navigation},
  year = 	 2016,
  pages = 	 {1-3},
  address={Stockholm, Sweden},
  month = 	 {May},
  abstract = 	 {Abstract:},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  label ={N8}, 
  pdf = ""
}

@InProceedings{XanthidisOceans2016,
  author = 	 {Marios Xanthidis and Alberto Quattrini Li and Ioannis Rekleitis},
  title = 	 {Shallow Coral Reef Surveying by Inexpensive Drifters},
  booktitle = {MTS/IEEE OCEANS - Shanghai},
  year = 	 2016,
  pages = 	 {1 - 9},
  month = 	 {Apr.},
  abstract = {Abstract: Coral reefs exhibit the highest biodiversity in the ocean and are an extremely vulnerable ecosystem. Monitoring the state of the reefs is a tedious process performed by human divers which can be automated. This paper presents the use of several inexpensive drifting sensor nodes in order to reconstruct a visual mosaic of a shallow coral reef. The drifters produce geo-referenced visual data from a downward facing camera while floating above a shallow-water coral reef. The vision is augmented with inertial data enabling the recovery of the drifter's attitude. A brief description of the drifters together with a framework to produce visual mosaics are discussed. Experimental results from a deployment over the Folkestone Marine Reserve in Barbados demonstrating the utility of our approach are presented.},
 category = {Editorials; Lightly Refereed Conference and Workshop Papers},
 label ={N7}, 
  pdf = "RekleitisOceansShanghai2016.pdf"
 }

@InProceedings{RekleitisIROSWork2015,
  author = 	 {Ioannis Rekleitis and Philippe Babin and Andrew DePriest and Sourav Das and Olivier Falardeau and Olivier Dugas and Philippe Giguere},
  title = 	 {Experiments in Quadrotor Formation Flying Using On-Board Relative Localization},
  booktitle = {Vision-based Control and Navigation of Small, Lightweight UAVs Workshop, IEEE/RSJ International Conference on Intelligent Robots and Systems},
  year = 	 2015,
  month = 	 {Oct.},
  address = 	 {Hamburg, Germany},
  abstract = {Abstract: Formation flying of aerial robots has many appli- cations, such as surveillance, coordinated transport of heavy objects, convoying, and others. Current research on formation control often relies on the use of an external motion capture equipment to track the pose of each individual robot. In order to deploy multiple Unmanned Aerial Vehicles (UAVs) to arbitrary environments, an alternative to motion capture or differential GPS is needed. In this paper, we show a proof of concept of a bearing-only relative localization approach in the context of maintaining flying formations, by recovering the 6 Degree of Freedom (DoF) relative pose between a pair of flying vehicles. This relative pose, estimated from a pair of images from mutually observing robots, is directly used to guide a follower quadrotor to keep a fixed position with respect to a leader. Experimental results from indoor and outdoor flying of two off-the-shelf quadrotors (Parrot AR.Drone 2.0) are presented.},
category = {Editorials; Lightly Refereed Conference and Workshop Papers},
label ={N6},
pdf = "ARdroneCL_Workshop.pdf"
}

@inproceedings{RekleitisHRI2015b,
 author = {Wu, Xian and Stuck, Rachel E. and Rekleitis, Ioannis and Beer, Jenay M.},
 title = {Towards a Human Factors Model for Underwater Robotics},
 booktitle = {Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts},
 series = {HRI'15 Extended Abstracts},
 year = {2015},
 isbn = {978-1-4503-3318-4},
 location = {Portland, OR, USA},
 pages = {159--160},
 numpages = {2},
 doi = {10.1145/2701973.2702029},
 acmid = {2702029},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {underwater robotics},
abstract = {Abstract: The goal of this study is to understand the factors between a human and semi-Autonomous Underwater Vehicles (sAUVs) from a HRI perspective. A SME interview approach was used to analyze video data of operators interacting with sAUVs. The results suggest considerations for the capabilities and limitations of the human and robot, in relation to the dynamic demands of the task and environment. We propose a preliminary human factors model to depict these components and discuss how they interact.},
category = {Editorials; Lightly Refereed Conference and Workshop Papers},
label ={N5},
pdf = "HRI2015b.pdf"
} 



@inproceedings{RekleitisHRI2015a,
 author = {St-Onge, David and Reeves, Nicolas and Gigu\`{e}re, Philippe and Sharf, Inna and Dudek, Gregory and Rekleitis, Ioannis and Br\`{e}ches, Pierre-Yves and Abouzakhm, Patrick and Babin, Philippe},
 title = {AEROSTABILES: A New Approach to HRI Researches},
 booktitle = {Annual ACM/IEEE International Conference on Human-Robot Interaction Extended Abstracts},
 series = {HRI'15 Extended Abstracts},
 year = {2015},
 isbn = {978-1-4503-3318-4},
 location = {Portland, OR, USA},
 pages = {277--277},
 numpages = {1},
 doi = {10.1145/2701973.2702095},
 acmid = {2702095},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {autonomous blimps, human-robot interaction, hybrid performance, localization and control, robotic art},
abstract = {Abstract:  Initiated as a research-creation project by professor and artist Nicolas Reeves, the Aerostabile project quickly expanded to include researchers and artists from a wide range of disciplines. Its current phase brings together four robotic and research-creation labs with various expertises in unstable and dynamic environments. The first group, under the direction of professor Inna Sharf, is based at the department of mechanical engineering at University McGill. It works on control and modeling of autonomous blimps for satellite emulation. The second group is headed by professor Philippe Giguere from University Laval. It focuses on localization systems for robots operating in unknown outdoor environments. The third group is also from McGill, but this time from the computer science department. Headed by professor Gregory Dudek, it investigates the challenges presented by autonomous underwater robots, and by their interactions with human divers. The last team is based at the UQAM school of design. It is headed by professor Nicolas Reeves and engineer David St-Onge. It works on installations and performances in digital and algorithmic arts, and on the impact of new medias and technologies on the fields of art, architecture and design. The Aerostabile project pushes the boundaries of engineering and art by proposing a close hybridization of the two disciplines. It redefines the human-robot interaction paradigm, working specifically on the new interfaces required by the specific nature and context of emerging robotic systems. Multidisciplinary approaches are required to seamlessly integrate aesthetics, grace and precision. Amongst the tools and strategies developed by the research team, one of the most important is the organization of regular meetings similar to art residencies, which are structured around the framework of engineering software and hardware integration workshops. During such meetings, which occur twice a year, the four groups work together with engineers and artists from different disciplines. These intense collaborative events happen in spaces large enough to fit at least two 225-cm floating robotic cubes called "Tryphons", the latest models of a series of flying automata developed by Reeves and St-Onge. Fruitful questions and discussions emerge from these residencies, leading to new questions and development axis both in art and engineering. Whenever possible, they happen in public spaces, allowing direct contact with all kinds of audiences and with inspiring media artists and creators-researchers. The specific constraints of out-of-the-lab environments raise new problematics for all engineers, while the encounter between different academic cultures influence the development priorities. At the end of our journey, on top of the engineering papers that will be published, we aim to produce the first hybrid performance involving four performers interacting with four fully autonomous aerobots.},
category = {Editorials; Lightly Refereed Conference and Workshop Papers},
label ={N4},
vid = "HRI2015a.mp4"
}

@InProceedings{GirdharRSSWork2012,
  author = 	 {Yogesh Girdhar and Anqi Xu and Florian Shkurti and Juan Camilo Gamboa Higuera and Malika Meghjani and Philippe Giguere and Ioannis Rekleitis and Gregory Dudek},
  title = 	 {Monitoring Marine Environments using a Team of Heterogeneous Robots},
  booktitle = {Robotics Science and Systems, Workshop on Robotics for Environmental Monitoring (WREM 2012)},
  year = 	 2012,
  address = 	 {Sydney, Australia},
  abstract = {Abstract:},
 category = {Editorials; Lightly Refereed Conference and Workshop Papers},
 label ={N3},
  pdf = ""
}





@Article{RekleitisEditorial2009,
  author = 	 {Robert Sim and Greg Mori and Ioannis  Rekleitis},
  title = 	 {Editorial, Second and Third Canadian Conferences on Computer and Robot Vision},
  Journal = {Image and Vision Computing, Special Issue},
  year = 2009 ,
  volune = 27,
  pages=1,
  abstract = {Abstract:},
  category = {Editorials; Lightly Refereed Conference and Workshop Papers},
  label ={N2},
  pdf = ""
  }


@InProceedings{Rekleitis2002a,
author ={Ioannis Rekleitis and Gregory Dudek and Evangelos~E. Milios},
title ={On the Positional Uncertainty of Multi-Robot Cooperative Localization},
booktitle = {Multi-Robot Systems Workshop, Naval Research Laboratory},
month ={Mar.},
year =2002,
address = 	 {Washington, DC, USA},
abstract = {Abstract: This paper  deals with terrain mapping and position estimation using multiple robots. Here we will discuss work where a larger group of robots can mutually estimate one another's position (in 2D or 3D) and uncertainty using a sample-based  (particle filter) model of uncertainty. Our prior work has dealt with a pair of robots that estimate one another's position using visual tracking and coordinated motion and we extend these results and consider a richer set of sensing and motion options. In particular, we focus on issues related to confidence estimation for groups of more than two robots.},
category = {Editorials; Lightly Refereed Conference and Workshop Papers},
label ={N1},
pdf = "mrworkshop.pdf"
}


@TechReport{RekleitisTR0402,
  author = 	 {Ioannis  Rekleitis},
  title = 	 {A Particle Filter Tutorial for Mobile Robot Localization},
  institution =  {Centre for Intelligent Machines, McGill University},
  year = 	 2004,
  month = 	 {Jan.},
  number =	 {TR-CIM-04-02},
  address =	 {3480 University St., Montreal, Qu\'ebec, CANADA H3A 2A7},
abstract = {Abstract: This tutorial is extracted from my Ph.D. thesis [1]. It is available also as a technical report (TR-CIM-04-02)[2]. It is placed online to help other researchers that are interested in implementing a particle filter for mobile robots.},
category = {Technical Reports},
label ={T4},
pdf = "particletutorial.pdf"
}


@TechReport{RekleitisTR0002,
  author = 	 {Ioannis Rekleitis},
  title = 	 {Bug Algorithm Survey},
  institution =  {Centre for Intelligent Machines, McGill University},
  year = 	 2000,
  month = 	 {Jan.},
  number = 	 {TR-CIM-00-02},
  address = 	 {3480 University St., Montreal, Québec, Canada H3A 2A7},
  abstract = {Abstract: A brief report on the different variants of the bug planning algorithm.},
category = {Technical Reports},
  label ={T3}
}

@TechReport{Rekleitis1999b,
author = {Ioannis  Rekleitis and Gregory Dudek and Evangelos Milios},
title = {Multi-Robot Collaboration for Robust Exploration},
institution = {York University},
year = 1999,
  month = 	 {Oct.},
number = {CS-1999-10},
abstract = {Abstract: This report presents a new sensing modality for multirobot exploration. The approach is based on using a pair of robots that observe each other's behavior, acting in concert to reduce odometry errors. We assume the robots can both directly sense nearby obstacles and see each other. The proposed approach improves the quality of the map by reducing the inaccuracies that occur over time from dead reckoning errors. Furthermore, by exploiting the ability of the robots to see each other, we can detect opaque obstacles in the environment independently of their surface reflectance properties. Two different algorithms, based on the size of the environment, are introduced, with a complexity analysis, and experimental results in simulation and with real robots.},
category = {Technical Reports},
label ={T2},
pdf = "CS-1999-10.pdf"
}

@TechReport{RekleitisTR9701,
  author = 	 {Ioannis  Rekleitis and Gregory Dudek and Evangelos Milios},
  title = 	 {Optimality proof for the trapezoid decomposition},
  institution =  {Centre for Intelligent Machines, McGill University},
  year = 	 1997,
  number = 	 {TR-CIM-97-01},
  address = 	 {3480 University St., Montreal, Québec, Canada H3A 2A7},
  month = 	 {Jan.},
abstract = {Abstract: This report contains the details of the optimality proof },
category = {Technical Reports},
label ={T1}
}



